{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[\"disease_progression\"] = y\n",
    "# X\n",
    "import pandas as pd\n",
    "import os\n",
    "from magpy.oracles.oracles import linear, BaseOracle\n",
    "from magpy.search.pcskeleton import pc_skeleton, parallel_pc_skeleton\n",
    "import logging\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    _SETUP\n",
    "except NameError:\n",
    "    os.chdir(\"..\")\n",
    "    _SETUP = True\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmagpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meffects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     EffectEstimator,\n\u001b[1;32m      3\u001b[0m     CategoricalTreatmentParams,\n\u001b[1;32m      4\u001b[0m     CategoricalOutcomeParams,\n\u001b[1;32m      5\u001b[0m     ContinuousTreatmentParams,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, RandomForestRegressor\n",
      "File \u001b[0;32m~/magpy/src/magpy/estimation/effects.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Union\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTClassifier, BaseXClassifier\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmagpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalEstimator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmagpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDataManager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataTypeManager, prep_data\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/causalml/inference/meta/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LRSRegressor, BaseSLearner, BaseSRegressor, BaseSClassifier\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     XGBTRegressor,\n\u001b[1;32m      4\u001b[0m     MLPTRegressor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     BaseTClassifier,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseXLearner, BaseXRegressor, BaseXClassifier\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/causalml/inference/meta/slearner.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdummy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyRegressor\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLearner\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/statsmodels/api.py:142\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_constant, categorical\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdoc\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m tsa\n\u001b[1;32m    144\u001b[0m load \u001b[38;5;241m=\u001b[39m load_pickle\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/statsmodels/tsa/api.py:73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima_process\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArmaProcess, arma_generate_sample\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetools\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexponential_smoothing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ETSModel\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m filters, bk_filter, cf_filter, hp_filter\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STLForecast\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/statsmodels/tsa/exponential_smoothing/ets.py:167\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa_model\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtsbase\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexponential_smoothing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexponential_smoothing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ets_smooth\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmooth\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexponential_smoothing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    169\u001b[0m     _initialization_simple,\n\u001b[1;32m    170\u001b[0m     _initialization_heuristic,\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsatools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m freq_to_period\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from magpy.estimation.effects import (\n",
    "    EffectEstimator,\n",
    "    CategoricalTreatmentParams,\n",
    "    CategoricalOutcomeParams,\n",
    "    ContinuousTreatmentParams,\n",
    ")\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "covariates = [\n",
    "    \"weather_1\",\n",
    "    \"day_of_week\",\n",
    "    # \"dph_col_grp_description\",\n",
    "    # \"party1_move_pre_acc\",\n",
    "    # \"party2_move_pre_acc\",\n",
    "    # \"type_of_collision\",\n",
    "    # \"road_cond_1\",\n",
    "]\n",
    "\n",
    "effect_estimation = EffectEstimator(\n",
    "    night_accidents,\n",
    "    classifier=RandomForestClassifier,\n",
    "    classifier_kwargs={\"max_depth\": 4},\n",
    "    regressor=RandomForestRegressor,\n",
    "    regressor_kwargs={\"max_depth\": 4},\n",
    ")\n",
    "results = effect_estimation.estimate_ate(\n",
    "    treatment=CategoricalTreatmentParams(\n",
    "        column=\"lighting\",\n",
    "        treatment_classes=[\"Dark - Street Lights\"],\n",
    "    ),\n",
    "    outcome=CategoricalOutcomeParams(\n",
    "        column=\"collision_severity\",\n",
    "        base_classes=[\"Fatal\", \"Injury (Severe)\", \"Injury (Other Visible)\"],\n",
    "    ),\n",
    "    covariates=covariates,\n",
    "    max_classes=5,\n",
    ")\n",
    "\n",
    "print(results.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from typing import List, Union, Optional\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "\n",
    "def nn(x):\n",
    "    return 1 / (numpy.sqrt(2 * numpy.pi)) * numpy.exp(-((x) ** 2) / 2)\n",
    "\n",
    "\n",
    "class DebiasedML:\n",
    "    \"\"\"\n",
    "    A class implementing Double/Debiased Machine Learning for treatment effect estimation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    learner : BaseEstimator\n",
    "        The base ML model to use for nuisance estimation (e.g., LGBMRegressor)\n",
    "    cv_splits : int, default=5\n",
    "        Number of cross-validation splits for nuisance estimation\n",
    "    final_learner : Optional[BaseEstimator], default=None\n",
    "        The ML model to use for final CATE estimation. If None, uses the same as learner\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    debias_model_ : BaseEstimator\n",
    "        Fitted model for debiasing treatment\n",
    "    denoise_model_ : BaseEstimator\n",
    "        Fitted model for denoising outcome\n",
    "    final_model_ : BaseEstimator\n",
    "        Fitted model for CATE estimation\n",
    "    treatment_mean_ : float\n",
    "        Mean of the treatment variable\n",
    "    outcome_mean_ : float\n",
    "        Mean of the outcome variable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        treatment_learner: BaseEstimator,\n",
    "        outcome_learner: BaseEstimator,\n",
    "        final_learner: Optional[BaseEstimator] = None,\n",
    "        cv_splits: int = 5,\n",
    "    ):\n",
    "        self.treatment_learner = treatment_learner\n",
    "        self.outcome_learner = outcome_learner\n",
    "        self.final_learner = final_learner\n",
    "        self.cv_splits = cv_splits\n",
    "        self.epsilon = 1e-6\n",
    "        self.outcome_type = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        treatment: str,\n",
    "        outcome: str,\n",
    "        covariates: List[str],\n",
    "        outcome_type: str = \"continuous\",\n",
    "    ) -> \"DebiasedML\":\n",
    "        \"\"\"\n",
    "        Fit the Double/Debiased ML model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Input dataframe\n",
    "        treatment : str\n",
    "            Name of treatment column\n",
    "        outcome : str\n",
    "            Name of outcome column\n",
    "        covariates : List[str]\n",
    "            List of covariate column names\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        self : DebiasedML\n",
    "            The fitted model\n",
    "        \"\"\"\n",
    "        # Store column names for later use\n",
    "        self.treatment_ = treatment\n",
    "        self.outcome_ = outcome\n",
    "        self.covariates_ = covariates\n",
    "        self.outcome_type = outcome_type\n",
    "\n",
    "        # Store means for later use in counterfactual predictions\n",
    "        self.treatment_mean_ = df[treatment].mean()\n",
    "        self.outcome_mean_ = df[outcome].mean()\n",
    "\n",
    "        # Create and fit the debiasing model for treatment\n",
    "        self.debias_model_ = clone(self.treatment_learner)\n",
    "        treatment_pred = cross_val_predict(\n",
    "            self.debias_model_, df[covariates], df[treatment], cv=self.cv_splits\n",
    "        )\n",
    "        self.debias_model_.fit(df[covariates], df[treatment])\n",
    "\n",
    "        # Modify the outcome prediction part based on outcome type\n",
    "        self.denoise_model_ = clone(self.outcome_learner)\n",
    "        if self.outcome_type in [\"binary\", \"multiclass\"]:\n",
    "            # Get probability predictions instead of class predictions\n",
    "            outcome_pred = cross_val_predict(\n",
    "                self.denoise_model_,\n",
    "                df[covariates],\n",
    "                df[outcome],\n",
    "                cv=self.cv_splits,\n",
    "                method=\"predict_proba\",  # Use probabilities for classification\n",
    "            )\n",
    "            # For binary, take only the positive class probability\n",
    "            if self.outcome_type == \"binary\":\n",
    "                outcome_pred = outcome_pred[:, 1]\n",
    "\n",
    "            outcome_res = df[outcome] - outcome_pred\n",
    "\n",
    "            # logloss = numpy.log(outcome_pred) * df[outcome] + numpy.log(\n",
    "            #     1 - outcome_pred\n",
    "            # ) * (1 - df[outcome])\n",
    "\n",
    "            # outcome_res = (numpy.exp(-logloss) - 1) * (df[outcome] - 1 / 2) * 2\n",
    "\n",
    "            # outcome_res = expit(outcome_res)\n",
    "\n",
    "        else:  # continuous case\n",
    "            outcome_pred = cross_val_predict(\n",
    "                self.denoise_model_, df[covariates], df[outcome], cv=self.cv_splits\n",
    "            )\n",
    "            outcome_res = df[outcome] - outcome_pred\n",
    "\n",
    "        self.denoise_model_.fit(df[covariates], df[outcome])\n",
    "\n",
    "        # Calculate residuals\n",
    "        treatment_res = df[treatment] - treatment_pred\n",
    "\n",
    "        # Fit final CATE model using the R-learner approach\n",
    "        weights = treatment_res**2\n",
    "\n",
    "        signs = numpy.sign(treatment_res)\n",
    "        tikhonov_adj = (1 - numpy.abs(signs)) * self.epsilon + signs * self.epsilon\n",
    "        transformed_target = outcome_res / (treatment_res + tikhonov_adj)\n",
    "\n",
    "        self.final_model_ = clone(self.final_learner)\n",
    "        self.final_model_.fit(df[covariates], transformed_target, sample_weight=weights)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_ite(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get Individual Treatment Effects for new data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Dataframe containing covariates for prediction\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Array of individual treatment effects\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"final_model_\"):\n",
    "            raise ValueError(\"Model must be fitted before getting ITE\")\n",
    "\n",
    "        return self.final_model_.predict(df[self.covariates_])\n",
    "\n",
    "    def counterfactual_prediction(\n",
    "        self, df: pd.DataFrame, treatment_value: Union[float, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Make counterfactual predictions for specific treatment values.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Dataframe containing covariates for prediction\n",
    "        treatment_value : Union[float, np.ndarray]\n",
    "            Treatment value(s) for counterfactual prediction\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Array of counterfactual predictions\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"final_model_\"):\n",
    "            raise ValueError(\n",
    "                \"Model must be fitted before making counterfactual predictions\"\n",
    "            )\n",
    "\n",
    "        # Get baseline prediction\n",
    "        if self.outcome_type == \"binary\":\n",
    "            baseline = self.denoise_model_.predict_proba(df[self.covariates_])\n",
    "            baseline = baseline[:, 1]\n",
    "\n",
    "        elif self.outcome_type == \"continuous\":\n",
    "            baseline = self.denoise_model_.predict(df[self.covariates_])\n",
    "\n",
    "        # Get treatment effect\n",
    "        ite = self.get_ite(df)\n",
    "\n",
    "        # Calculate treatment deviation from mean\n",
    "        if isinstance(treatment_value, (int, float)):\n",
    "            treatment_dev = treatment_value - self.treatment_mean_\n",
    "        else:\n",
    "            treatment_dev = np.array(treatment_value) - self.treatment_mean_\n",
    "\n",
    "        # Calculate counterfactual\n",
    "\n",
    "        d = {\n",
    "            \"baseline\": baseline,\n",
    "            \"addition\": (ite * treatment_dev),\n",
    "            \"result\": baseline + (ite * treatment_dev),\n",
    "        }\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49961\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DebiasedML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDebiasedML\u001b[49m(\n\u001b[1;32m     25\u001b[0m     treatment_learner\u001b[38;5;241m=\u001b[39mLGBMRegressor(),\n\u001b[1;32m     26\u001b[0m     outcome_learner\u001b[38;5;241m=\u001b[39mLGBMClassifier(),\n\u001b[1;32m     27\u001b[0m     final_learner\u001b[38;5;241m=\u001b[39mLGBMRegressor(),\n\u001b[1;32m     28\u001b[0m     cv_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     33\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m     34\u001b[0m     treatment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     outcome_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DebiasedML' is not defined"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from numpy.random import normal\n",
    "import pandas\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    k = 1\n",
    "    N = 100_000\n",
    "    z = normal(0, 1, N)\n",
    "    x = z + normal(0, 1, N)\n",
    "    y = z + k * x + normal(0, 1, N)\n",
    "    yB = y > 0\n",
    "    df = pandas.DataFrame({\"z\": z, \"x\": x, \"y\": yB, \"y_c\": y})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "print(df[\"y\"].mean())\n",
    "\n",
    "# Initialize the model\n",
    "model = DebiasedML(\n",
    "    treatment_learner=LGBMRegressor(),\n",
    "    outcome_learner=LGBMClassifier(),\n",
    "    final_learner=LGBMRegressor(),\n",
    "    cv_splits=5,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    df=df,\n",
    "    treatment=\"x\",\n",
    "    outcome=\"y\",\n",
    "    covariates=[\"z\"],\n",
    "    outcome_type=\"binary\",\n",
    ")\n",
    "\n",
    "# Get individual treatment effects\n",
    "ite = model.get_ite(df)\n",
    "\n",
    "# Make counterfactual predictions\n",
    "# cf_pred = model.counterfactual_prediction(df, treatment_value=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.counterfactual_prediction(df=df, treatment_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18918000000000001"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"y_c\"] + 1 > 1).mean() - (df[\"y_c\"] > 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56492"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19378384614322294"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res[\"addition\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026256429288702254"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"result\"].mean() - res[\"baseline\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027945690952334967"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027109999999999967"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"y_c\"] + 0.1 > 1).mean() - (df[\"y_c\"] > 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.5, random_state=42)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[531], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m DebiasedML(\n\u001b[1;32m      6\u001b[0m     treatment_learner\u001b[38;5;241m=\u001b[39mLinearRegression(),\n\u001b[1;32m      7\u001b[0m     outcome_learner\u001b[38;5;241m=\u001b[39mLinearRegression(),\n\u001b[1;32m      8\u001b[0m     final_learner\u001b[38;5;241m=\u001b[39mLinearRegression(),\n\u001b[1;32m      9\u001b[0m     cv_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtreatment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisease_progression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbmi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Get individual treatment effects\u001b[39;00m\n\u001b[1;32m     21\u001b[0m ite \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_ite(test_df)\n",
      "Cell \u001b[0;32mIn[263], line 88\u001b[0m, in \u001b[0;36mDebiasedML.fit\u001b[0;34m(self, df, treatment, outcome, covariates, outcome_type)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcome_type \u001b[38;5;241m=\u001b[39m outcome_type\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Store means for later use in counterfactual predictions\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreatment_mean_ \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtreatment\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcome_mean_ \u001b[38;5;241m=\u001b[39m df[outcome]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Create and fit the debiasing model for treatment\u001b[39;00m\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/magpy/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = DebiasedML(\n",
    "    treatment_learner=LinearRegression(),\n",
    "    outcome_learner=LinearRegression(),\n",
    "    final_learner=LinearRegression(),\n",
    "    cv_splits=5,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    df=train_df,\n",
    "    treatment=\"age\",\n",
    "    outcome=\"disease_progression\",\n",
    "    covariates=[\"bmi\", \"bp\"],\n",
    ")\n",
    "\n",
    "# Get individual treatment effects\n",
    "ite = model.get_ite(test_df)\n",
    "\n",
    "# Make counterfactual predictions\n",
    "cf_pred = model.counterfactual_prediction(test_df, treatment_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.59084772832838"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"cf_pred\"] = cf_pred\n",
    "test_df[\"cf_pred\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.80094742994571"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv(\"data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"outcome\"] = df[\"CLASS\"] == \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 30.935100\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.276875\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.044375\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.167787\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.465962\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.578020\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 672, number of negative: 128\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.840000 -> initscore=1.658228\n",
      "[LightGBM] [Info] Start training from score 1.658228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 672, number of negative: 128\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.840000 -> initscore=1.658228\n",
      "[LightGBM] [Info] Start training from score 1.658228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 672, number of negative: 128\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.840000 -> initscore=1.658228\n",
      "[LightGBM] [Info] Start training from score 1.658228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 672, number of negative: 128\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 44\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.840000 -> initscore=1.658228\n",
      "[LightGBM] [Info] Start training from score 1.658228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 672, number of negative: 128\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.840000 -> initscore=1.658228\n",
      "[LightGBM] [Info] Start training from score 1.658228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 840, number of negative: 160\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.840000 -> initscore=1.658228\n",
      "[LightGBM] [Info] Start training from score 1.658228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.021231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = DebiasedML(\n",
    "    treatment_learner=LGBMRegressor(),\n",
    "    outcome_learner=LGBMClassifier(),\n",
    "    final_learner=LGBMRegressor(),\n",
    "    cv_splits=5,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    df=df,\n",
    "    treatment=\"BMI\",\n",
    "    outcome=\"outcome\",\n",
    "    covariates=[\"AGE\"],\n",
    "    outcome_type=\"binary\",\n",
    ")\n",
    "\n",
    "# Get individual treatment effects\n",
    "ite = model.get_ite(df)\n",
    "\n",
    "# Make counterfactual predictions\n",
    "cf_pred = model.counterfactual_prediction(df, treatment_value=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.000893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.000347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.001520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.000768\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.003949\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.000581\n",
      "[LightGBM] [Info] Number of positive: 39851, number of negative: 40149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498138 -> initscore=-0.007450\n",
      "[LightGBM] [Info] Start training from score -0.007450\n",
      "[LightGBM] [Info] Number of positive: 39851, number of negative: 40149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498138 -> initscore=-0.007450\n",
      "[LightGBM] [Info] Start training from score -0.007450\n",
      "[LightGBM] [Info] Number of positive: 39851, number of negative: 40149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498138 -> initscore=-0.007450\n",
      "[LightGBM] [Info] Start training from score -0.007450\n",
      "[LightGBM] [Info] Number of positive: 39851, number of negative: 40149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498138 -> initscore=-0.007450\n",
      "[LightGBM] [Info] Start training from score -0.007450\n",
      "[LightGBM] [Info] Number of positive: 39852, number of negative: 40148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498150 -> initscore=-0.007400\n",
      "[LightGBM] [Info] Start training from score -0.007400\n",
      "[LightGBM] [Info] Number of positive: 49814, number of negative: 50186\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498140 -> initscore=-0.007440\n",
      "[LightGBM] [Info] Start training from score -0.007440\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.072429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0757836493998312"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from numpy.random import normal\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    k = 0.3\n",
    "    N = 100_000\n",
    "    z = normal(0, 1, N)\n",
    "    x = 1 * z + normal(0, 1, N)\n",
    "    y = 1 * z + k * x + normal(0, 1, N)\n",
    "    yB = y > 0\n",
    "    df = pandas.DataFrame({\"z\": z, \"x\": x, \"y\": yB})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "# Initialize the model\n",
    "model = DebiasedML(\n",
    "    treatment_learner=LGBMRegressor(),\n",
    "    outcome_learner=LGBMClassifier(),\n",
    "    final_learner=LGBMRegressor(),\n",
    "    cv_splits=5,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    df=df,\n",
    "    treatment=\"x\",\n",
    "    outcome=\"y\",\n",
    "    covariates=[\"z\"],\n",
    "    outcome_type=\"binary\",\n",
    ")\n",
    "\n",
    "# Get individual treatment effects\n",
    "ite = model.get_ite(df)\n",
    "\n",
    "# Make counterfactual predictions\n",
    "cf_pred = model.counterfactual_prediction(df, treatment_value=50)\n",
    "\n",
    "numpy.exp(ite).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401731</td>\n",
       "      <td>-0.793020</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.048442</td>\n",
       "      <td>-1.646158</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173569</td>\n",
       "      <td>-0.442551</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.958120</td>\n",
       "      <td>0.306413</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.545612</td>\n",
       "      <td>-1.540028</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>-0.093600</td>\n",
       "      <td>-0.096106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.391440</td>\n",
       "      <td>-0.989830</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.164485</td>\n",
       "      <td>0.773824</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-0.641621</td>\n",
       "      <td>-1.433162</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-0.599568</td>\n",
       "      <td>-0.750361</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              z         x      y\n",
       "0      0.401731 -0.793020   True\n",
       "1     -2.048442 -1.646158  False\n",
       "2      0.173569 -0.442551   True\n",
       "3      0.958120  0.306413   True\n",
       "4     -0.545612 -1.540028  False\n",
       "...         ...       ...    ...\n",
       "99995 -0.093600 -0.096106   True\n",
       "99996  0.391440 -0.989830  False\n",
       "99997  0.164485  0.773824  False\n",
       "99998 -0.641621 -1.433162  False\n",
       "99999 -0.599568 -0.750361  False\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12143650107261279"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_n_bigger_than_zero(kx):\n",
    "    return (kx + normal(0, 1, 100_000) > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "z = [prob_n_bigger_than_zero(kx) for kx in numpy.arange(0, 1, 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61594"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_n_bigger_than_zero(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1309974d0>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numpy.arange(0, 1, 0.05), numpy.array(z) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpy.estimation.effects import (\n",
    "    EffectEstimator,\n",
    "    CategoricalTreatmentParams,\n",
    "    CategoricalOutcomeParams,\n",
    "    ContinuousTreatmentParams,\n",
    "    ContinuousOutcomeParams,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PolynomialRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, degree=2):\n",
    "        self.degree = degree\n",
    "        self.poly = PolynomialFeatures(degree=self.degree)\n",
    "        self.linear = LinearRegression()\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # Reshape X if needed\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "\n",
    "        # Transform features to polynomial features\n",
    "        X_poly = self.poly.fit_transform(X)\n",
    "\n",
    "        # Fit linear regression on polynomial features\n",
    "        self.linear.fit(X_poly, y, sample_weight=sample_weight)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Reshape X if needed\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "\n",
    "        # Transform features and predict\n",
    "        X_poly = self.poly.transform(X)\n",
    "        return self.linear.predict(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='x' column='y_c'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from magpy.estimation.effects import (\n",
    "    EffectEstimator,\n",
    "    CategoricalTreatmentParams,\n",
    "    CategoricalOutcomeParams,\n",
    "    ContinuousTreatmentParams,\n",
    "    ContinuousOutcomeParams,\n",
    ")\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    noise = 0.01\n",
    "    k = 1\n",
    "    N = 100_000\n",
    "    z = normal(0, 1, N)\n",
    "    x = 1 * z + normal(0, 1, N)\n",
    "    y = 1 * z + k * x * z * z + normal(0, 1, N)\n",
    "    yB = y > 0\n",
    "    df = pandas.DataFrame({\"z\": z, \"x\": x, \"y\": yB, \"y_c\": y})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "effect_estimation = EffectEstimator(\n",
    "    data=df,\n",
    "    classifier=LGBMClassifier,\n",
    "    regressor=PolynomialRegressor,\n",
    ")\n",
    "\n",
    "results = effect_estimation.fit_predict(\n",
    "    treatment=ContinuousTreatmentParams(column=\"x\"),\n",
    "    # outcome=CategoricalOutcomeParams(column=\"y\", base_classes=[False]),\n",
    "    outcome=ContinuousOutcomeParams(column=\"y_c\"),\n",
    "    covariates=[\"z\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='x' column='y_c'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    }
   ],
   "source": [
    "results = effect_estimation.fit_predict(\n",
    "    treatment=ContinuousTreatmentParams(column=\"x\"),\n",
    "    # outcome=CategoricalOutcomeParams(column=\"y\", base_classes=[False]),\n",
    "    outcome=ContinuousOutcomeParams(column=\"y_c\"),\n",
    "    covariates=[\"z\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_treatment_effect</th>\n",
       "      <th>std_treatment_effect</th>\n",
       "      <th>baseline_incidence_mean</th>\n",
       "      <th>baseline_incidence_number</th>\n",
       "      <th>baseline_treated_mean</th>\n",
       "      <th>baseline_treated_number</th>\n",
       "      <th>number_of_samples</th>\n",
       "      <th>significance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-4.625, -0.841]</th>\n",
       "      <td>2.212779</td>\n",
       "      <td>1.676951</td>\n",
       "      <td>-5.233847</td>\n",
       "      <td>-104676.935844</td>\n",
       "      <td>-1.397593</td>\n",
       "      <td>-27951.854312</td>\n",
       "      <td>20000</td>\n",
       "      <td>90.649568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.841, -0.254]</th>\n",
       "      <td>0.277535</td>\n",
       "      <td>0.185518</td>\n",
       "      <td>-0.724759</td>\n",
       "      <td>-14495.174222</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-10489.404643</td>\n",
       "      <td>20000</td>\n",
       "      <td>93.266568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.254, 0.249]</th>\n",
       "      <td>-0.008445</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-117.936609</td>\n",
       "      <td>-0.007421</td>\n",
       "      <td>-148.418933</td>\n",
       "      <td>20000</td>\n",
       "      <td>66.471727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.249, 0.841]</th>\n",
       "      <td>0.303120</td>\n",
       "      <td>0.196039</td>\n",
       "      <td>0.716910</td>\n",
       "      <td>14338.191985</td>\n",
       "      <td>0.524038</td>\n",
       "      <td>10480.750598</td>\n",
       "      <td>20000</td>\n",
       "      <td>93.896659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.841, 3.999]</th>\n",
       "      <td>2.275033</td>\n",
       "      <td>1.693703</td>\n",
       "      <td>5.244674</td>\n",
       "      <td>104893.481951</td>\n",
       "      <td>1.401275</td>\n",
       "      <td>28025.500940</td>\n",
       "      <td>20000</td>\n",
       "      <td>91.039370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean_treatment_effect  std_treatment_effect  \\\n",
       "quantile                                                        \n",
       "(-4.625, -0.841]               2.212779              1.676951   \n",
       "(-0.841, -0.254]               0.277535              0.185518   \n",
       "(-0.254, 0.249]               -0.008445              0.019854   \n",
       "(0.249, 0.841]                 0.303120              0.196039   \n",
       "(0.841, 3.999]                 2.275033              1.693703   \n",
       "\n",
       "                  baseline_incidence_mean  baseline_incidence_number  \\\n",
       "quantile                                                               \n",
       "(-4.625, -0.841]                -5.233847             -104676.935844   \n",
       "(-0.841, -0.254]                -0.724759              -14495.174222   \n",
       "(-0.254, 0.249]                 -0.005897                -117.936609   \n",
       "(0.249, 0.841]                   0.716910               14338.191985   \n",
       "(0.841, 3.999]                   5.244674              104893.481951   \n",
       "\n",
       "                  baseline_treated_mean  baseline_treated_number  \\\n",
       "quantile                                                           \n",
       "(-4.625, -0.841]              -1.397593            -27951.854312   \n",
       "(-0.841, -0.254]              -0.524470            -10489.404643   \n",
       "(-0.254, 0.249]               -0.007421              -148.418933   \n",
       "(0.249, 0.841]                 0.524038             10480.750598   \n",
       "(0.841, 3.999]                 1.401275             28025.500940   \n",
       "\n",
       "                  number_of_samples  significance  \n",
       "quantile                                           \n",
       "(-4.625, -0.841]              20000     90.649568  \n",
       "(-0.841, -0.254]              20000     93.266568  \n",
       "(-0.254, 0.249]               20000     66.471727  \n",
       "(0.249, 0.841]                20000     93.896659  \n",
       "(0.841, 3.999]                20000     91.039370  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.covariate_groups[\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='z', ylabel='effect'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=\"z\", y=\"effect\", data=results.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.007120\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.009412\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.010266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.008510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.007524\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score -0.008566\n",
      "[LightGBM] [Info] Number of positive: 52069, number of negative: 27931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650863 -> initscore=0.622833\n",
      "[LightGBM] [Info] Start training from score 0.622833\n",
      "[LightGBM] [Info] Number of positive: 52069, number of negative: 27931\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650863 -> initscore=0.622833\n",
      "[LightGBM] [Info] Start training from score 0.622833\n",
      "[LightGBM] [Info] Number of positive: 52069, number of negative: 27931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650863 -> initscore=0.622833\n",
      "[LightGBM] [Info] Start training from score 0.622833\n",
      "[LightGBM] [Info] Number of positive: 52069, number of negative: 27931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650863 -> initscore=0.622833\n",
      "[LightGBM] [Info] Start training from score 0.622833\n",
      "[LightGBM] [Info] Number of positive: 52068, number of negative: 27932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650850 -> initscore=0.622778\n",
      "[LightGBM] [Info] Start training from score 0.622778\n",
      "[LightGBM] [Info] Number of positive: 65086, number of negative: 34914\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650860 -> initscore=0.622822\n",
      "[LightGBM] [Info] Start training from score 0.622822\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DebiasedML(\n\u001b[1;32m      2\u001b[0m     treatment_learner\u001b[38;5;241m=\u001b[39mLGBMRegressor(),\n\u001b[1;32m      3\u001b[0m     outcome_learner\u001b[38;5;241m=\u001b[39mLGBMClassifier(),\n\u001b[1;32m      4\u001b[0m     final_learner\u001b[38;5;241m=\u001b[39mLGBMRegressor(),\n\u001b[1;32m      5\u001b[0m     cv_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtreatment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutcome_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Get individual treatment effects\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ite \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_ite(df)\n",
      "Cell \u001b[0;32mIn[5], line 137\u001b[0m, in \u001b[0;36mDebiasedML.fit\u001b[0;34m(self, df, treatment, outcome, covariates, outcome_type)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Fit final CATE model using the R-learner approach\u001b[39;00m\n\u001b[1;32m    135\u001b[0m weights \u001b[38;5;241m=\u001b[39m treatment_res\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 137\u001b[0m signs \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39msign(treatment_res)\n\u001b[1;32m    138\u001b[0m tikhonov_adj \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m numpy\u001b[38;5;241m.\u001b[39mabs(signs)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m+\u001b[39m signs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon\n\u001b[1;32m    139\u001b[0m transformed_target \u001b[38;5;241m=\u001b[39m outcome_res \u001b[38;5;241m/\u001b[39m (treatment_res \u001b[38;5;241m+\u001b[39m tikhonov_adj)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "model = DebiasedML(\n",
    "    treatment_learner=LGBMRegressor(),\n",
    "    outcome_learner=LGBMClassifier(),\n",
    "    final_learner=LGBMRegressor(),\n",
    "    cv_splits=5,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    df=df,\n",
    "    treatment=\"x\",\n",
    "    outcome=\"y\",\n",
    "    covariates=[\"z\"],\n",
    "    outcome_type=\"binary\",\n",
    ")\n",
    "\n",
    "# Get individual treatment effects\n",
    "ite = model.get_ite(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16264227044086368"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Urea\", \"Cr\", \"HbA1c\", \"Chol\", \"TG\", \"HDL\", \"LDL\", \"VLDL\", \"BMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Urea' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Urea' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Cr' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Cr' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='HbA1c' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='HbA1c' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Chol' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Chol' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='TG' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='TG' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='HDL' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='HDL' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='LDL' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='LDL' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='VLDL' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='VLDL' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='BMI' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='BMI' column='CLASS' base_classes=['N'] treatment_classes=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/src/magpy/estimation/effects.py:495: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouper = output_data.groupby(\"quantile\")\n"
     ]
    }
   ],
   "source": [
    "from magpy.estimation.effects import EffectEstimator\n",
    "from magpy.estimation.effects import (\n",
    "    ITEResults,\n",
    "    ContinuousOutcomeParams,\n",
    "    ContinuousTreatmentParams,\n",
    "    CategoricalOutcomeParams,\n",
    "    CategoricalTreatmentParams,\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFRegressor\n",
    "\n",
    "\n",
    "df = pandas.read_csv(\"data/diabetes.csv\")\n",
    "\n",
    "columns = [\"Urea\", \"Cr\", \"HbA1c\", \"Chol\", \"TG\", \"HDL\", \"LDL\", \"VLDL\", \"BMI\"]\n",
    "\n",
    "\n",
    "effect_estimation = EffectEstimator(\n",
    "    data=df,\n",
    "    classifier=XGBClassifier,\n",
    "    regressor=XGBRFRegressor,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "results_1 = {}\n",
    "for col in columns:\n",
    "    results[col] = effect_estimation.fit_predict(\n",
    "        treatment=ContinuousTreatmentParams(column=col),\n",
    "        # outcome=CategoricalOutcomeParams(column=\"y\", base_classes=[False]),\n",
    "        outcome=CategoricalOutcomeParams(column=\"CLASS\", base_classes=[\"N\"]),\n",
    "        covariates=[\"AGE\", \"Gender\"] + list(set(columns) - set([col])),\n",
    "    )\n",
    "    results_1[col] = effect_estimation.fit_predict(\n",
    "        treatment=ContinuousTreatmentParams(column=col),\n",
    "        # outcome=CategoricalOutcomeParams(column=\"y\", base_classes=[False]),\n",
    "        outcome=CategoricalOutcomeParams(column=\"CLASS\", base_classes=[\"N\"]),\n",
    "        covariates=[\"AGE\", \"Gender\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 38/66 [00:00<00:00, 202.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n",
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 209.88it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 194.23it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 179.21it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 213.00it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 488.48it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 1772.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from magpy.oracles.mixed import MixedDataOracle\n",
    "from magpy.search.pcskeleton import pc_skeleton\n",
    "\n",
    "\n",
    "oracle = MixedDataOracle(df.drop(columns=[\"No_Pation\", \"ID\"]))\n",
    "mat, sepsets = pc_skeleton(\n",
    "    oracle,\n",
    "    intersection_or_union=\"intersection\",\n",
    "    nodes=df.drop(columns=[\"No_Pation\", \"ID\"]).columns,\n",
    ")\n",
    "# skeleton.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urea</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HbA1c</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chol</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TG</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VLDL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASS</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender  AGE  Urea   Cr  HbA1c  Chol   TG  HDL  LDL  VLDL  BMI  CLASS\n",
       "Gender     0.0  0.0   0.0  1.0    1.0   0.0  0.0  1.0  0.0   1.0  0.0    1.0\n",
       "AGE        0.0  0.0   1.0  0.0    1.0   0.0  0.0  0.0  0.0   1.0  1.0    1.0\n",
       "Urea       0.0  1.0   0.0  1.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0    0.0\n",
       "Cr         1.0  0.0   1.0  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0    0.0\n",
       "HbA1c      1.0  1.0   0.0  0.0    0.0   1.0  1.0  0.0  0.0   0.0  1.0    1.0\n",
       "Chol       0.0  0.0   0.0  0.0    1.0   0.0  1.0  1.0  1.0   0.0  0.0    1.0\n",
       "TG         0.0  0.0   0.0  0.0    1.0   1.0  0.0  1.0  0.0   1.0  0.0    1.0\n",
       "HDL        1.0  0.0   0.0  0.0    0.0   1.0  1.0  0.0  1.0   0.0  1.0    0.0\n",
       "LDL        0.0  0.0   0.0  0.0    0.0   1.0  0.0  1.0  0.0   1.0  0.0    0.0\n",
       "VLDL       1.0  1.0   0.0  0.0    0.0   0.0  1.0  0.0  1.0   0.0  1.0    1.0\n",
       "BMI        0.0  1.0   0.0  0.0    1.0   0.0  0.0  1.0  0.0   1.0  0.0    1.0\n",
       "CLASS      1.0  1.0   0.0  0.0    1.0   1.0  1.0  0.0  0.0   1.0  1.0    0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urea -0.004608371 -0.0054543074\n",
      "Cr 8.2976614e-05 -0.00051524746\n",
      "HbA1c -0.00043262576 0.03523011\n",
      "Chol 0.03003706 0.02431885\n",
      "TG 0.022227777 0.028655615\n",
      "HDL -0.0019866747 -0.006998428\n",
      "LDL 0.014109211 0.0074671567\n",
      "VLDL -0.034883864 0.06337716\n",
      "BMI 0.004961482 0.020210225\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    print(col, results[col].data[\"effect\"].mean(), results_1[col].data[\"effect\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"data/BankChurners.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLIENTNUM',\n",
       " 'Attrition_Flag',\n",
       " 'Customer_Age',\n",
       " 'Gender',\n",
       " 'Dependent_count',\n",
       " 'Education_Level',\n",
       " 'Marital_Status',\n",
       " 'Income_Category',\n",
       " 'Card_Category',\n",
       " 'Months_on_book',\n",
       " 'Total_Relationship_Count',\n",
       " 'Months_Inactive_12_mon',\n",
       " 'Contacts_Count_12_mon',\n",
       " 'Credit_Limit',\n",
       " 'Total_Revolving_Bal',\n",
       " 'Avg_Open_To_Buy',\n",
       " 'Total_Amt_Chng_Q4_Q1',\n",
       " 'Total_Trans_Amt',\n",
       " 'Total_Trans_Ct',\n",
       " 'Total_Ct_Chng_Q4_Q1',\n",
       " 'Avg_Utilization_Ratio',\n",
       " 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
       " 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "excl = [\n",
    "    \"CLIENTNUM\",\n",
    "    \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\n",
    "    \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/190 [00:00<00:30,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 21/190 [00:01<00:12, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n",
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/190 [00:01<00:17,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n",
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 25/190 [00:02<00:19,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DGESDDM parameter number 10 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:07<00:00, 26.03it/s]\n",
      "100%|██████████| 190/190 [00:17<00:00, 10.96it/s]\n",
      " 65%|██████▌   | 124/190 [00:10<00:07,  9.19it/s]ERROR:root:Error running Credit_Limit -- Total_Trans_Amt | ('Avg_Open_To_Buy', 'Total_Revolving_Bal')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Credit_Limit -- Avg_Utilization_Ratio | ('Avg_Open_To_Buy', 'Total_Revolving_Bal')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Total_Revolving_Bal -- Total_Trans_Amt | ('Avg_Open_To_Buy', 'Credit_Limit')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      " 91%|█████████ | 172/190 [00:10<00:00, 46.03it/s]ERROR:root:Error running Total_Revolving_Bal -- Avg_Utilization_Ratio | ('Avg_Open_To_Buy', 'Credit_Limit')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Avg_Open_To_Buy -- Avg_Utilization_Ratio | ('Total_Revolving_Bal', 'Credit_Limit')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "100%|██████████| 190/190 [00:10<00:00, 18.56it/s]\n",
      " 75%|███████▌  | 143/190 [00:06<00:01, 25.26it/s]ERROR:root:Error running Credit_Limit -- Avg_Utilization_Ratio | ('Gender', 'Avg_Open_To_Buy', 'Total_Revolving_Bal')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Credit_Limit -- Avg_Utilization_Ratio | ('Avg_Open_To_Buy', 'Total_Revolving_Bal', 'Card_Category')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Total_Revolving_Bal -- Avg_Utilization_Ratio | ('Income_Category', 'Avg_Open_To_Buy', 'Credit_Limit')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Total_Revolving_Bal -- Avg_Utilization_Ratio | ('Avg_Open_To_Buy', 'Credit_Limit', 'Marital_Status')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Avg_Open_To_Buy -- Avg_Utilization_Ratio | ('Income_Category', 'Total_Revolving_Bal', 'Credit_Limit')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Avg_Open_To_Buy -- Avg_Utilization_Ratio | ('Total_Revolving_Bal', 'Credit_Limit', 'Marital_Status')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "100%|██████████| 190/190 [00:07<00:00, 26.76it/s]\n",
      " 63%|██████▎   | 119/190 [00:02<00:02, 26.86it/s]ERROR:root:Error running Credit_Limit -- Avg_Utilization_Ratio | ('Gender', 'Avg_Open_To_Buy', 'Total_Revolving_Bal', 'Card_Category')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Total_Revolving_Bal -- Avg_Utilization_Ratio | ('Income_Category', 'Avg_Open_To_Buy', 'Credit_Limit', 'Marital_Status')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "ERROR:root:Error running Avg_Open_To_Buy -- Avg_Utilization_Ratio | ('Income_Category', 'Total_Revolving_Bal', 'Credit_Limit', 'Marital_Status')\n",
      "ERROR:root:not enough values to unpack (expected 1, got 0)\n",
      "100%|██████████| 190/190 [00:02<00:00, 66.42it/s]\n",
      "100%|██████████| 190/190 [00:00<00:00, 401.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from magpy.oracles.mixed import MixedDataOracle\n",
    "from magpy.search.pcskeleton import pc_skeleton\n",
    "\n",
    "\n",
    "oracle = MixedDataOracle(df.drop(columns=excl), threshold=0.1)\n",
    "mat, sepsets = pc_skeleton(\n",
    "    oracle,\n",
    "    intersection_or_union=\"intersection\",\n",
    "    nodes=df.drop(columns=excl).columns,\n",
    ")\n",
    "# skeleton.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Attrition_Flag', 'Customer_Age', 'Gender', 'Dependent_count',\n",
       "       'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category',\n",
       "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
       "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
       "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
       "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.loc[\"Attrition_Flag\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_covariates = [\n",
    "    \"Customer_Age\",\n",
    "    \"Gender\",\n",
    "    \"Dependent_count\",\n",
    "    \"Education_Level\",\n",
    "    \"Marital_Status\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Months_Inactive_12_mon',\n",
       " 'Total_Ct_Chng_Q4_Q1',\n",
       " 'Total_Revolving_Bal']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def associated_with_cols(col1, col2):\n",
    "    col1_associated = mat.loc[col1][mat.loc[col1] == 1.0].index\n",
    "    col2_associated = mat.loc[col2][mat.loc[col2] == 1.0].index\n",
    "    return list(set(col1_associated) & set(col2_associated))\n",
    "\n",
    "\n",
    "associated_with_cols(\"Income_Category\", \"Attrition_Flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Generating propensity score\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column='Income_Category' base_classes=[] treatment_classes=['$120K +'] column='Attrition_Flag' base_classes=[] treatment_classes=['Attrited Customer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/andre/magpy/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "INFO:causalml:Calibrating propensity scores.\n",
      "INFO:causalml:Error metrics for group True\n",
      "INFO:causalml:     AUC   (Control):     0.7963\n",
      "INFO:causalml:     AUC (Treatment):     0.9640\n",
      "INFO:causalml:Log Loss   (Control):     0.3669\n",
      "INFO:causalml:Log Loss (Treatment):     0.2213\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:499: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  \n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:514: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  \"baseline_incidence_number\": baseline_incidence_number,\n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:499: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  \n",
      "/Users/andre/magpy/src/magpy/estimation/effects.py:514: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  \"baseline_incidence_number\": baseline_incidence_number,\n"
     ]
    }
   ],
   "source": [
    "from magpy.estimation.effects import EffectEstimator\n",
    "from magpy.estimation.effects import (\n",
    "    ITEResults,\n",
    "    ContinuousOutcomeParams,\n",
    "    ContinuousTreatmentParams,\n",
    "    CategoricalOutcomeParams,\n",
    "    CategoricalTreatmentParams,\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "\n",
    "effect_estimation = EffectEstimator(\n",
    "    data=df,\n",
    "    classifier=XGBClassifier,\n",
    "    regressor=XGBRegressor,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "results_1 = {}\n",
    "# for col in [\"Income_Category\"]:\n",
    "# results[col] =\n",
    "result = effect_estimation.fit_predict(\n",
    "    # treatment=ContinuousTreatmentParams(column=col),\n",
    "    treatment=CategoricalTreatmentParams(\n",
    "        column=\"Income_Category\", treatment_classes=[\"$120K +\"]\n",
    "    ),\n",
    "    # outcome=CategoricalOutcomeParams(column=\"y\", base_classes=[False]),\n",
    "    outcome=CategoricalOutcomeParams(\n",
    "        column=\"Attrition_Flag\", treatment_classes=[\"Attrited Customer\"]\n",
    "    ),\n",
    "    covariates=general_covariates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04203077204079174"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data.effect.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Customer_Age', 'Gender', 'Dependent_count', 'Education_Level', 'Marital_Status'])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.covariate_groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_treatment_effect</th>\n",
       "      <th>std_treatment_effect</th>\n",
       "      <th>baseline_incidence_mean</th>\n",
       "      <th>baseline_incidence_number</th>\n",
       "      <th>baseline_treated_mean</th>\n",
       "      <th>baseline_treated_number</th>\n",
       "      <th>number_of_samples</th>\n",
       "      <th>significance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(25.999, 39.0]</th>\n",
       "      <td>0.136088</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.136542</td>\n",
       "      <td>278</td>\n",
       "      <td>0.050098</td>\n",
       "      <td>102</td>\n",
       "      <td>2036</td>\n",
       "      <td>65.407626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(39.0, 44.0]</th>\n",
       "      <td>-0.027724</td>\n",
       "      <td>0.259263</td>\n",
       "      <td>0.173446</td>\n",
       "      <td>371</td>\n",
       "      <td>0.061711</td>\n",
       "      <td>132</td>\n",
       "      <td>2139</td>\n",
       "      <td>54.255106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(44.0, 48.0]</th>\n",
       "      <td>0.041185</td>\n",
       "      <td>0.280701</td>\n",
       "      <td>0.167099</td>\n",
       "      <td>322</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>106</td>\n",
       "      <td>1927</td>\n",
       "      <td>55.827804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(48.0, 53.0]</th>\n",
       "      <td>0.041330</td>\n",
       "      <td>0.238136</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>325</td>\n",
       "      <td>0.116698</td>\n",
       "      <td>246</td>\n",
       "      <td>2108</td>\n",
       "      <td>56.883916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(53.0, 73.0]</th>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.294451</td>\n",
       "      <td>0.172666</td>\n",
       "      <td>331</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>141</td>\n",
       "      <td>1917</td>\n",
       "      <td>52.920207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean_treatment_effect  std_treatment_effect  \\\n",
       "quantile                                                      \n",
       "(25.999, 39.0]               0.136088              0.342997   \n",
       "(39.0, 44.0]                -0.027724              0.259263   \n",
       "(44.0, 48.0]                 0.041185              0.280701   \n",
       "(48.0, 53.0]                 0.041330              0.238136   \n",
       "(53.0, 73.0]                 0.021589              0.294451   \n",
       "\n",
       "                baseline_incidence_mean  baseline_incidence_number  \\\n",
       "quantile                                                             \n",
       "(25.999, 39.0]                 0.136542                        278   \n",
       "(39.0, 44.0]                   0.173446                        371   \n",
       "(44.0, 48.0]                   0.167099                        322   \n",
       "(48.0, 53.0]                   0.154175                        325   \n",
       "(53.0, 73.0]                   0.172666                        331   \n",
       "\n",
       "                baseline_treated_mean  baseline_treated_number  \\\n",
       "quantile                                                         \n",
       "(25.999, 39.0]               0.050098                      102   \n",
       "(39.0, 44.0]                 0.061711                      132   \n",
       "(44.0, 48.0]                 0.055008                      106   \n",
       "(48.0, 53.0]                 0.116698                      246   \n",
       "(53.0, 73.0]                 0.073552                      141   \n",
       "\n",
       "                number_of_samples  significance  \n",
       "quantile                                         \n",
       "(25.999, 39.0]               2036     65.407626  \n",
       "(39.0, 44.0]                 2139     54.255106  \n",
       "(44.0, 48.0]                 1927     55.827804  \n",
       "(48.0, 53.0]                 2108     56.883916  \n",
       "(53.0, 73.0]                 1917     52.920207  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.covariate_groups[\"Customer_Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model(model, X, feature_names=None):\n",
    "    \"\"\"\n",
    "    Generate SHAP explanations for a scikit-learn model\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : sklearn estimator\n",
    "        Fitted scikit-learn model to explain\n",
    "    X : pd.DataFrame or np.array\n",
    "        Data to explain predictions for\n",
    "    feature_names : list, optional\n",
    "        List of feature names if X is not a DataFrame\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    shap.Explanation\n",
    "        SHAP explanation object containing various visualization methods\n",
    "    \"\"\"\n",
    "    import shap\n",
    "\n",
    "    # Convert numpy array to DataFrame if needed\n",
    "    if not isinstance(X, pd.DataFrame) and feature_names is not None:\n",
    "        X = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "    # Initialize explainer based on model type\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        explainer = (\n",
    "            shap.TreeExplainer(model)\n",
    "            if hasattr(model, \"estimators_\")\n",
    "            else shap.KernelExplainer(model.predict_proba, X)\n",
    "        )\n",
    "    else:\n",
    "        explainer = (\n",
    "            shap.TreeExplainer(model)\n",
    "            if hasattr(model, \"estimators_\")\n",
    "            else shap.KernelExplainer(model.predict, X)\n",
    "        )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Print summary plots\n",
    "    print(\"\\nFeature Importance Plot:\")\n",
    "    shap.summary_plot(shap_values, X)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        print(\"\\nFeature Importance Bar Plot:\")\n",
    "        shap.summary_plot(shap_values[1], X, plot_type=\"bar\")\n",
    "\n",
    "        print(\"\\nDetailed Feature Impact Plot:\")\n",
    "        shap.dependence_plot(\"rank(0)\", shap_values[1], X)\n",
    "    else:\n",
    "        print(\"\\nFeature Importance Bar Plot:\")\n",
    "        shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "\n",
    "        print(\"\\nDetailed Feature Impact Plot:\")\n",
    "        shap.dependence_plot(\"rank(0)\", shap_values, X)\n",
    "\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_model(effect_estimation.final_model_, df[general_covariates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total_Revolving_Bal\n",
       "0.0        8039.114251\n",
       "132.0      9580.000000\n",
       "134.0      8018.000000\n",
       "145.0      9104.000000\n",
       "154.0     34516.000000\n",
       "              ...     \n",
       "2511.0     2835.000000\n",
       "2512.0     3317.000000\n",
       "2513.0     9904.000000\n",
       "2514.0     3826.000000\n",
       "2517.0     9115.500000\n",
       "Name: Credit_Limit, Length: 1974, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Total_Revolving_Bal\")[\"Credit_Limit\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1480d0c50>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHdCAYAAAAEt+BKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABc+UlEQVR4nO3dd1hT5/8+8DuAIrJFAQFBQNCiQLVaGW5cVcQ9cG8cbfWjxdVlWzdabZ3gqGLFVXexikIFGWoddRRxoCKi4mKLgJDfH/6SrzEBQwgGj/fruryEc55znvc5SbhztigzM1MMIiIieu9paboAIiIiUg+GOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIKp8qN+/fx9r1qxB79690aRJE9SpUwfOzs4YNmwYzp49K9d+4cKFMDExKfVfSkqKwn4iIyPRrVs32NjYoF69evD19UV0dHSpdd28eRMjR46Eg4MDLC0t4e3tjY0bN0IsFqtt2YmIiMpDR9MFvE1ISAhWrFgBe3t7tG/fHrVr10ZycjLCw8MRHh6ODRs2oE+fPnLT+fv7w9bWVm64sbGx3LCdO3ciICAAtWvXhr+/PwBg37596NWrFzZv3oyePXvKtE9KSkLnzp3x4sUL9OrVC3Xr1kVERASmT5+OpKQkBAUFqWnpiYiIlCfKzMys0puWBw8eRK1atdCqVSuZ4fHx8ejZsyf09fVx7do16OrqAni1pb548WIcOnQIrVu3fuv8MzMz4e7uDh0dHcTExMDa2hoAkJaWhjZt2gAA/v33XxgaGkqn6datG+Lj47F792506tQJAFBYWIiePXsiISEBERER+PTTT9Wy/O+z3Nxc5ObmarqM946BgQEMDAw0XQapCT8H5cfPgOqq/Ja6n5+fwuFeXl5o3bo1oqKikJiYiKZNm6o0//379yMrKwuzZ8+WBjoAWFtbY9y4cVi0aBH+/PNP6Rb8zZs3ER8fj9atW0sDHQCqV6+Or7/+Gr6+vtiyZQtDHcD58+cRGxur6TLeO61atZJ+oaT3Hz8H5cfPgOqqfKiXpVq1agAAbW1tuXHx8fE4d+4ctLS04ODggHbt2in85if5sHXo0EFunI+PDxYtWoS4uDhpqJfV3tPTE/r6+oiLi1N9oQSkWbNmcHZ21nQZcp48eYKDBw/Cz88PtWvX1nQ5criFIiz8HJQfPwOqe29DPTU1FSdOnIClpSUaN24sN37hwoUyvxsbG2PRokXScJZITk4GADg6OsrNQzJM0ub1nx0cHOTaa2trw87ODklJSXj58iV0dMpevS9evChz/PtOR0cHJiYmmi5DTkFBAQDA0NCwStYHCP+98SHh50A1H8pnoEaNGmqd33sZ6kVFRQgICEBBQQHmzp0rs6XepEkTrFq1Cq1atYKlpSXS09Nx9OhRLFiwAJMmTYKxsTG6desmbZ+dnQ0AMDIykutHchxd0ub1nxWdcCeZpqSkBLm5uW/9oNy/fx/FxcXKLTSpTUZGBgAgPT0dhYWFGq6GSDP4OaganJyc1Dq/9y7US0pKMGnSJMTHx2PEiBEYNGiQzPgePXrI/G5nZ4fx48ejYcOG6NWrF+bNmycT6ppkZWWl6RI+SNWrVwcAWFhYwMLCQsPVEGkGPwfC9F6FeklJCSZPnozdu3djwIABWL58udLTtm3bFvb29khMTER2drZ0y1zyf3Z2NmrVqiUzTU5Ojkyb13/OyspS2E9OTg5EIpFSx4TUvduFlCO5UkJXV5evAX2w+DkQpip/8xkJyRb69u3b0a9fP6xduxZaWuUr38zMDACQn58vHabouLmEouPtkp9v3bol1764uBgpKSmws7N76/F0IiIidXsvQl0S6Dt27ECfPn0QHBys8Iz3suTl5SEpKQn6+vrScAcAb29vAEBUVJTcNJGRkTJt3tY+ISEBeXl5Mu2JiIjelSof6pJd7jt27ECvXr0QEhJSaqDn5OTg5s2bcsPz8/MxZcoU5OTkoFevXjJb0b1794aRkRFCQkKQlpYmHZ6Wlob169fDzMwMvr6+0uFOTk7w8vLCyZMncezYMenwwsJCzJ8/HwAwfPjwCi83ERFReVX5fcSLFy/G9u3bYWBggAYNGii8BWv37t3h5uaGZ8+eoUWLFtLrQi0sLPDo0SNER0cjLS0NLi4u+Omnn2SmNTExQVBQEAICAtC2bVv07t0bwKvbxD579gy//fabzN3kAGDZsmXo0qULhgwZgt69e8PS0hIRERG4evUqxo0bh5YtW1beCiEiIipFlQ/1u3fvAnh1q8WlS5cqbGNraws3NzeYmppi7NixOHfuHI4dO4bMzEzo6enB2dkZAQEBGDduHPT09OSmHzhwIMzMzLBs2TKEhYVBJBLB3d0dgYGBaNeunVz7jz76CJGRkZg3bx4iIiLw/PlzODo6YunSpRgzZoxal5+IiEhZVf7e70Tq9vDhQ2zatAmjR4+GpaWlpssh0gh+DoSpyh9TJyIiIuUw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQVT7U79+/jzVr1qB3795o0qQJ6tSpA2dnZwwbNgxnz55VOE12djbmzJmDJk2awNzcHK6urvj222+Rm5ursH1JSQmCg4Ph5eUFS0tLODo6YsyYMbhz506pdUVGRqJbt26wsbFBvXr14Ovri+joaHUsMhERkUqqfKiHhIRgzpw5uHPnDtq3b4/PP/8cHh4eOHz4MDp37oy9e/fKtM/Ly0P37t2xZs0aODs7Y9KkSXBycsLKlSvh5+eHFy9eyPUxdepUzJw5E2KxGAEBAfDx8cGhQ4fQvn17JCcny7XfuXMn+vbti+vXr8Pf3x+DBg1CUlISevXqhQMHDlTauiAiIiqLjqYLeJtmzZrhzz//RKtWrWSGx8fHo2fPnpg2bRq6d+8OXV1dAMAvv/yCy5cvY+rUqZg7d660/dy5c7FixQqsWbMG06ZNkw6PiYlBaGgovLy8sH//flSvXh0A0L9/f/Tv3x+BgYEyXxwyMzMxY8YMmJmZITo6GtbW1gBefTFo06YNpk2bhg4dOsDQ0LCyVgkREZFCSoW6u7t7hTsSiUT4999/yz2dn5+fwuFeXl5o3bo1oqKikJiYiKZNm0IsFmPr1q0wMDBAYGCgTPvAwEBs2LABoaGhMqEeGhoKAPj666+lgQ4AnTp1QqtWrRAVFYXU1FTUq1cPALB//35kZWVh9uzZ0kAHAGtra4wbNw6LFi3Cn3/+CX9//3IvKxERUUUoFep3796tcEcikajC83hTtWrVAADa2toAgOTkZDx48AA+Pj7Q19eXaauvr4+WLVsiMjIS9+7dg42NDQAgNjYW+vr68PDwkJu/j48PYmNjERcXh0GDBknbA0CHDh0Utl+0aBHi4uKUCnVFhwKo8hUUFEj/52tAHyp+DqqGGjVqqHV+SoX6oUOH1NqpOqSmpuLEiROwtLRE48aNAUB6/NvBwUHhNA4ODoiMjERycjJsbGyQl5eHhw8fwsXFRfrF4M32r8/39Z8dHR3l2kuGKToOr8j9+/dRXFysVFtSn4yMDABAeno6CgsLNVwNkWbwc1A1ODk5qXV+SoX6m8ezNa2oqAgBAQEoKCjA3LlzpYGcnZ0NADA2NlY4nZGRkUw7yf+S4W9r/7ZpJMfRX29fFisrK6XakXpJDrNYWFjAwsJCw9UQaQY/B8JU5U+Ue1NJSQkmTZqE+Ph4jBgxQrpb/H2k7t0upBzJSZW6urp8DeiDxc+BMFX5S9peV1JSgsmTJ2P37t0YMGAAli9fLjNesvWclZWlcPo3t7IVbYmX1f5t0+Tk5Mi1JyIielfUsqX++PFjXL58Gc+ePUNRUVGp7SpyRrhkC33Hjh3o168f1q5dCy0t2e8kkmPat27dUjgPyXBJO319fVhaWiIlJQXFxcVyx9XfbC/5+cKFC0hOTkatWrVk2pd1vJ2IiKiyVSjU7969i+nTpyMqKgpisfit7VUN9dcDvU+fPggODlZ4YpujoyPq1q2L06dPIy8vT+YM+Ly8PJw+fRp2dnbSM98BwNvbG3v27MGpU6fg7e0tM7/IyEgAry6fe739H3/8gaioKLRo0UJh+zfnQ0RE9C6ovPv9yZMn6Nq1K44fPw5LS0sYGBgAADw8PNCwYUNoa2tDLBajRo0a8PLykgnG8pDsct+xYwd69eqFkJAQhYEOvLpsbtiwYcjNzUVQUJDMuKCgIOTm5mLEiBEywyW/z58/X+YM0GPHjiE2NhYdOnSAra2tdHjv3r1hZGSEkJAQpKWlSYenpaVh/fr1MDMzg6+vr0rLSkREVBEqb6mvXLkSDx48wMiRI7F8+XJ89tlnOH36NA4fPgzg1Z3XVq9ejeXLl6NBgwZYsWKFSv0sXrwY27dvh4GBARo0aCAX1gDQvXt3uLm5AQCmTJmCw4cPY8WKFbh06RLc3d1x8eJFREVFoVmzZpg4caLMtG3atMHw4cMRGhqKtm3bonPnznj48CH27dsHU1NTLFmyRKa9iYkJgoKCEBAQgLZt26J3794AgH379uHZs2f47bffeDc5IiLSCJVD/dixY6hevTq+++47heNNTEzw9ddfw9zcHDNnzkSLFi0wZMiQcvcjufFNbm4uli5dqrCNra2tNNT19fURHh6ORYsW4dChQzh58iQsLCzw+eefY+bMmdDT05ObfsWKFXBxccGWLVuwbt066Ovrw9fXF99++y3s7e3l2g8cOBBmZmZYtmwZwsLCIBKJ4O7ujsDAQLRr167cy0hERKQOoszMzLcfDFfA2toaVlZW+OeffwBAuqX+6NEj6Oj833cFsVgMZ2dnODg44OjRo+qpmqgCHj58iE2bNmH06NGwtLTUdDlEGsHPgTBV6JK21y/dkpyU9vTpU5k2IpEI9erVQ1JSUkW6IiIiordQOdTr1q2Lx48fS3+XPPDk4sWLMu1KSkqQmprK2xASERFVMpVDvWHDhnj06JH0unRvb2+IxWIsXLgQmZmZ0nYLFy7EkydP4OzsXOFiiYiIqHQqnyjXuXNnHD58GDExMfDx8UGPHj1ga2uLixcvonHjxnB2dsbjx49x//59iEQijBs3Tp11ExER0RtUDvUePXqgsLBQelc1XV1d7Nq1C8OHD8f169elz06vVq0apk6diqFDh6qlYCIiIlJM5VCvVauW3NZ3w4YNcerUKZw7dw4pKSnQ09PDp59+itq1a1e4UCIiIiqb2p/SJhKJ0Lx5czRv3lzdsyYiIqIyvFdPaSMiIqLSqX1LPSIiAv/88w8yMjJQv3599OnTB1ZWVuruhoiIiN5QrlB/8OABvv/+e0RGRqKoqAgfffQRAgMD0bFjRzx//hwDBgxAfHy8zDQLFy7EmjVr0LNnT7UWTkRERLKUDvXc3Fx89tlnuHv3rvQxq2fOnMHgwYNx6NAhbNmyBXFxcahevTocHR0hFotx69YtPH/+HBMmTICbm5vC+6gTERGReih9TD04OBgpKSmoUaMGPv/8cyxZsgT9+/dHUVERli5dij179qBNmza4cuUK4uPjkZCQgIsXL8LT0xMFBQUIDg6uzOUgIiL64Cm9pf7XX39BJBJh8+bN6Ny5MwBg3LhxqFevHn7++Wfo6Ohg5cqVqFOnjnQaS0tLrF69Gs2bN0dMTIz6qyciIiIppbfUb9y4gTp16kgDXUJyUxkrKyvY2trKTWdvbw9ra2ukpqZWsFQiIiIqi9KhnpOTAxsbG7nh1tbWAF494KU0devWRV5engrlERERkbKUDnWxWIzq1avLDZcME4lEpXeixcvhiYiIKhvTloiISCDUfvMZereysrKQn5+v6TLeK0+ePJH5n5Sjp6cHY2NjTZdBRGUoV6j/+++/cHd3lxsuEolKHQcA6enpqlVHZcrKykJwcDBevnyp6VLeSwcPHtR0Ce8VHR0dBAQEMNiJqrByhfqLFy9w9+7dco8Dyj7mTqrJz8/Hy5cv0aBle+gZmWi6HBKw/OxM3Dz9N/Lz8xnqRFWY0qG+evXqyqyDKkDPyAT6pny8LRHRh07pUB88eHBl1kFEREQVpLGz33/++WdMnjxZU90TEREJjsZC/dixY9i+fbumuiciIhIcXqdOREQkEAx1IiIigWCoExERCQRDnYiISCAY6kRERALBUCciIhIIhjoREZFAMNSJiIgEgqFOREQkEAx1IiIigSjXo1fVaciQIWjbtq2muiciIhIcjYX60KFDNdU1ERGRIKkc6uV5wpq2tjYMDQ1hZ2cHLy8vNGnSRNVuiYiIqBQqh3pYWBgAQCQSSYeJxWLpz4qGS4Z5enpi9erVqF+/vqrdExER0RtUDvWZM2ciKysLGzduRHFxMVq2bAk3NzcYGBggNzcXly9fxqlTp6Cjo4PRo0dDR0cH169fx4kTJxAfHw8/Pz/ExMTAxMREjYtDRET04VI51CdMmAAfHx84Ojpi8+bNaNiwoVyb69evY8SIEYiIiEBkZCRMTExw9+5dDBo0CElJSVizZg3mzJlToQUgIiKiV1S+pG3x4sVISUlBWFiYwkAHAGdnZ2zbtg137tzBokWLAAC2trYIDg6GWCzGkSNHVO2eiIiI3qByqIeHh6Nhw4awt7cvs52DgwMaNWqEw4cPS4e5urrC1tYWt2/fVrV7IiIieoPKof7o0SNoaSk3uZaWFh49eiQzzNzcHEVFRap2T0RERG9QOdTNzMyQlJSE1NTUMtulpqbi6tWrMDMzkxmelZUFU1NTVbsnIiKiN6gc6p07d8bLly8xbNgw3L17V2Gb1NRUDBs2DCUlJejatat0+LNnz5CcnAw7OztVuyciIqI3qHz2++zZs3HkyBFcvHgRLVq0QJs2beDq6iq9pO3KlSuIjo5GYWEh6tati1mzZkmnDQsLQ0lJCdq1a6eOZSAiIiJUINTNzc0RHh6OcePG4fz58zh+/DgiIyOl4yU3nGnevDlCQkJQp04d6Tg/Pz/4+PjAxsamAqUTERHR6yp073cHBwdERkbi5MmTiIyMxI0bN5CXlwd9fX04OTnBx8cHrVu3lpvO1ta2It0SERGRAmp5oEvr1q0VhjcRERG9O3yeOhERkUAw1ImIiASiQrvfc3NzsWrVKhw5cgS3bt1Cbm5uqW1FIhGePn1ake6IiIioDCqH+qNHj9C1a1fcuXNH5pGrpVGmDREREalO5VCfP38+bt++DXNzc3z55Zf49NNPUadOHaVvHUtERETqpXKoHzt2DNra2vjjjz/g6uqqzpqIiIhIBSpvVj99+hQODg4MdCIioipC5VC3sLBA9erV1VkLERERVYDKod6tWzdcv34djx8/Vmc9REREpCKVQ33WrFkwNzfHpEmTkJ2drc6a5OzcuRNTp05Fu3btYG5uDhMTE2zbtk1h24ULF8LExKTUfykpKQqni4yMRLdu3WBjY4N69erB19cX0dHRpdZ08+ZNjBw5Eg4ODrC0tIS3tzc2btzIs/yJiEhjVD5R7q+//sLIkSOxZMkSfPLJJ+jXrx8aNGiAmjVrljqNv7+/Sn3NmzcPqampMDMzg4WFxVuf4S7pS9E95o2NjeWG7dy5EwEBAahdu7a0xn379qFXr17YvHkzevbsKdM+KSkJnTt3xosXL9CrVy/UrVsXERERmD59OpKSkhAUFKTSchIREVWEyqE+adIkiEQiiMViPHnyBMHBwW+dRtVQX7lyJRwcHGBra4vly5fjhx9+eOs0gwcPVup+9JmZmZgxYwbMzMwQHR0Na2trAMDUqVPRpk0bTJs2DR06dIChoaF0mmnTpiE7Oxu7d+9Gp06dAABff/01evbsifXr16N///749NNPVVpWIiIiVakc6l5eXhCJROqspVSV+dz1/fv3IysrC7Nnz5YGOgBYW1tj3LhxWLRoEf7880/pF5KbN28iPj4erVu3lgY6AFSvXh1ff/01fH19sWXLFoY6ERG9cyqHenh4uDrrULv4+HicO3cOWlpacHBwQLt27WBgYCDXLjY2FgDQoUMHuXE+Pj5YtGgR4uLipKFeVntPT0/o6+sjLi5OqRpfvHih9PIoUlBQUKHpicqroKCgwu9bqhokfz/4mmpWjRo11Do/tTx6tSpauHChzO/GxsZYtGiR3CGA5ORkAICjo6PcPCTDJG1e/9nBwUGuvba2Nuzs7JCUlISXL19CR6fs1Xv//n0UFxcrsTSKZWRkqDwtkSrS09NRWFio6TJIDSR/P/iaapaTk5Na5ye4UG/SpAlWrVqFVq1awdLSEunp6Th69CgWLFiASZMmwdjYGN26dZO2l5y5b2RkJDcvyXH018/ul/ys6IQ7yTQlJSXIzc2FiYlJmbVaWVmVa9nexPsE0LtmYWEBCwsLTZdBaiD5+8HXVFgEF+o9evSQ+d3Ozg7jx49Hw4YN0atXL8ybN08m1DWportddHV11VQJkXJ0dXXVvruQNEPy94OvqbAoFeru7u4AXu1y3rdvn8wwZYlEIvz777/lq06N2rZtC3t7eyQmJiI7O1u6ZS75Pzs7G7Vq1ZKZJicnR6bN6z9nZWUp7CcnJwcikUjh8XsiIqLKpFSo3717F4DslqVkmLLe1ZnyZTEzM8OtW7eQn58vDWdHR0dcuHABycnJcqGu6Hi75Odbt27Jzb+4uBgpKSmws7N76/F0IiIidVMqeQ4dOgQAMjeWkQx7X+Tl5SEpKQn6+vowMzOTDvf29sYff/yBqKgotGjRQmaayMhIaZvX2wNAVFQU/ve//8m0T0hIQF5eHnr16lVJS0FERFQ6pUK9VatWSg3TtJycHKSnp6NBgwYyw/Pz8zFlyhTk5ORgyJAhMlvRvXv3xvfff4+QkBAMHTpUeq16Wloa1q9fDzMzM/j6+krbOzk5wcvLCydPnsSxY8ek16oXFhZi/vz5AIDhw4dX9qISERHJeS/2EYeGhiIhIQEAkJiYCADYunWr9JpxT09PDB8+HM+ePUOLFi3QrFkzODs7w8LCAo8ePUJ0dDTS0tLg4uKCn376SWbeJiYmCAoKQkBAANq2bYvevXsDeHWb2GfPnuG3336TuZscACxbtgxdunTBkCFD0Lt3b1haWiIiIgJXr17FuHHj0LJly8peJURERHJUDvUZM2Zg8ODB+Pjjj9VYjmIJCQnYvn27zLBTp07h1KlT0t+HDx8OU1NTjB07FufOncOxY8eQmZkJPT09ODs7IyAgAOPGjYOenp7c/AcOHAgzMzMsW7YMYWFhEIlEcHd3R2BgoMK72X300UeIjIzEvHnzEBERgefPn8PR0RFLly7FmDFj1L78REREyhBlZmaq9FgxU1NTiEQiODs7w9/fHwMGDEDdunXVXR+V4eHDh9i0aRNcO/WGvmltTZdDApaX8QSXj+3D6NGjYWlpqelySA0kfz/4mgqLyo9e7dOnD2rUqIFr167hhx9+gKurK/r06YPdu3cjPz9fnTUSERGRElQO9Y0bN+LatWv49ddf4enpiZKSEvz9998ICAhAw4YN8fnnn+PkyZPqrJWIiIjKoHKoA69uiTps2DCEh4fj4sWL+Prrr9GgQQPk5ORg27Zt6NmzJ9zc3DB//nyZ+6cTERGR+lUo1F9Xr149fPXVVzhz5gwiIyMxduxYmJqaIjU1FcuWLeOjSImIiCqZ2kL9dc2aNUNQUBDOnDmDrl27QiwWQyxW6Xw8IiIiUpLar1MvKSnB8ePHsWPHDhw5ckT6nF7eNpWIiKhyqS1pL126hB07dmDPnj14/PixdMu8SZMmGDRoEAYMGKCuroiIiEiBCoV6eno6du3ahR07duDq1asAALFYDEtLS/Tr1w+DBg1C48aN1VIoERERlU3lUO/bty+io6NRUlICsVgMPT09dOvWDf7+/mjfvj20tCrlcD0RERGVQuVQj4qKgkgkgqenJwYNGoRevXrJ3SOd3o387ExNl0ACx/cY0ftB5VCfM2cOBg4cCFtbW3XWQyq4efpvTZdARERVgMqhHhgYqM46qAIatGwPPSMTTZdBApafnckvj0TvAV5nJgB6RiZ8oAsRESkX6m8+9lRV/v7+apkPERERyVMq1CdNmgSRSFThzhjqRERElUepUPfy8lJLqBMREVHlUSrUw8PDK7sOIiIiqiDeIYaIiEggePY7Eb33srKykJ+fr+ky3itPnjyR+Z+Uo6enB2NjY02XUSq1hPrFixcRERGBGzduICcnB4aGhnB2dkanTp3g7u6uji6IiBTKyspCcHAwXr58qelS3ksHDx7UdAnvFR0dHQQEBFTZYK9QqD979gyTJk1CREQEAMg8M10kEmHBggXo2rUrVq1ahVq1alWsUiIiBfLz8/Hy5UvehIkqneQmTPn5+cIL9YKCAvTu3RuXL1+GWCyGm5sbXFxcYGlpiYcPHyIxMRGXLl3CkSNH0KdPHxw9ehS6urrqrJ2ISIo3YSKqQKivX78ely5dgrW1NVavXo22bdvKtYmJicHkyZNx6dIlbNiwAZMnT65QsURERFQ6lc9+37dvH0QiEcLCwhQGOgC0adMG27Ztg1gsxt69e1UukoiIiN5O5VC/ceMGnJyc4ObmVmY7Nzc3ODs748aNG6p2RUREREpQOdSLioqgp6enVFs9PT0UFRWp2hUREREpQeVQt7a2RlJSEjIzM8tsl5GRgaSkJFhZWanaFRERESlB5VBv3749CgoKMGnSJLx48UJhmxcvXmDSpEkoLCxEx44dVS6SiIiI3k7ls9+nTp2KnTt34siRI3Bzc8PIkSPh4uICc3NzPHr0CImJidi8eTOePHkCQ0NDfPnll+qsm4iIiN6gcqhbW1sjLCwMI0eOxOPHj7F06VK5NmKxGLVr18bmzZthbW1doUKJiIiobBW6o1yrVq1w5swZbNiwAceOHcONGzeQm5sLAwMDODs7o3Pnzhg9ejTvJkdERPQOVPje77Vq1cKMGTMwY8YMddRDREREKuKjV4mIiARC5VD38vLCypUrkZ6ers56iIiISEUqh/rVq1fx/fffo3Hjxujfvz/27t2LgoICddZGRERE5aByqP/8889o0aIFiouLcfz4cYwdOxZOTk6YMmUK4uPj1VkjERERKUHlUB81ahSOHj2KCxcuYMaMGahfvz5ycnIQGhoKX19ffPzxx1i0aBHu3LmjxnKJiIioNBU+Ua5+/fqYPXs2zp8/jyNHjmDkyJEwNjZGSkoKlixZgmbNmuGzzz5DaGioOuolIiKiUqj17PeWLVti+fLluHbtGjZv3oyuXbtCR0cHp06dwtSpU9XZFREREb2hwtepK1K9enX4+fnB0NAQhYWFiIyMrIxuiIiI6DVqD/WrV69i+/bt+OOPP/Dw4UPp8I8++kjdXREREdFr1BLqT548wa5du7Bjxw5cuXIFwKv7vtepUwd9+/bFoEGD4O7uro6uiIiIqBQqh3phYSHCw8OxY8cOREVFobi4GGKxGLq6uvjss88waNAgdOzYEdra2uqsl4iIiEqhcqg7OTkhJycHYrEYwKuT5AYNGoTevXvD2NhYbQUSERGRclQO9ezsbNjZ2WHgwIHw9/dH/fr11VgWERERlZfKoX748GF4enqqsxYiIiKqAJWvU2egExERVS1qOfv9woULiI6ORlpaGvLz87Fq1SrpuIcPH6KoqAj16tVTR1dERERUigqFenp6OgICAhATEwPg1WVsIpFIJtTnzZuHsLAwHD16FC1atKhYtURERFQqlXe/5+bmokePHoiOjkbdunXh7+8Pa2truXaDBg2CWCzG4cOHK1QoERERlU3lUF+9ejVu3LiBzp074/Tp01i9erXCXeyenp7Q1dVFdHR0hQolIiKisqkc6gcPHoSOjg5WrlwJAwODUttpa2vDwcEBt2/fVrUrIiIiUoLKoX7nzh04ODjA3Nz8rW0NDAyQm5uraldERESkBJVDXSQSKd02MzMT+vr6qnZFRERESlA51G1tbZGSkoLnz5+X2e7Ro0dITk6Gs7Ozql0RERGRElQO9Y4dO6KwsBArVqwos92CBQsgFovRuXNnVbsiIiIiJagc6pMnT4aBgQGWLl2KOXPm4ObNmzLj//vvPwQEBGDLli0wMzPD2LFjK1wsERERlU7lm89YWFhg69atGDZsGNatW4d169ZJx5mZmUEsFkMsFsPQ0BCbN2+GiYmJOuolIiKiUqi8pQ4Abdu2RXR0NPr16wc9PT1pkJeUlKB69erw8/NDVFQUvL29K1Tkzp07MXXqVLRr1w7m5uYwMTHBtm3bSm2fnZ2NOXPmoEmTJjA3N4erqyu+/fbbUs/ALykpQXBwMLy8vGBpaQlHR0eMGTMGd+7cKbWPyMhIdOvWDTY2NqhXrx58fX15LT4REWlUhe/9bm9vj5CQELx8+RLJycnSM90bNGiAGjVqqKNGzJs3D6mpqTAzM4OFhQVSU1NLbZuXl4fu3bvj8uXL6NChA/r164dLly5h5cqViIuLw+HDh+Xqmjp1KkJDQ/HRRx8hICAADx48wP79+xEVFYXjx4/D0dFRpv3OnTsREBCA2rVrw9/fHwCwb98+9OrVC5s3b0bPnj3VstxERETlUaEt9dfp6OigYcOGaNmyJZo0aSITnFlZWViwYIHK8165ciUuXbqE5ORkjB49usy2v/zyCy5fvoypU6di7969mDt3Lvbu3YupU6fi/PnzWLNmjUz7mJgYhIaGwsvLC9HR0fjhhx8QEhKCbdu2ISMjA4GBgTLtMzMzMWPGDJiZmSE6OhpBQUEICgpCdHQ0atWqhWnTpiEnJ0flZSUiIlKV2kJdkaysLCxcuBBubm5YunSpyvNp164dbG1t39pOLBZj69atMDAwkAvjwMBAGBgYIDQ0VGa45Pevv/4a1atXlw7v1KkTWrVqhaioKJk9A/v370dWVhbGjx8vc697a2trjBs3Dk+fPsWff/6p0nISERFVRLlDPScnBwcOHMCvv/6KDRs24J9//pFr8/z5cyxevBju7u4ICgpCdnY2ateurZaCy5KcnIwHDx6gZcuWcje70dfXR8uWLXHnzh3cu3dPOjw2Nhb6+vrw8PCQm5+Pjw8AIC4uTqY9AHTo0EGp9kRERO9KuY6pHz58GJ9//jkyMzNlhrdr1w6///47atasiaNHj2LKlCl49OgRxGIx6tSpgy+++OKdXNKWnJwMAHBwcFA43sHBAZGRkUhOToaNjQ3y8vLw8OFDuLi4QFtbW2H71+f7+s9vHmd/fdjr7cvy4sULpdqVpqCgoELTE5VXQUFBhd+36sbPAb1r6vwcqOvcMwmlQ/3GjRsYPXq09ANkbGwsXbATJ07g66+/RsuWLTF58mSUlJTA3NwcX3zxBcaMGQM9PT21Fl2a7OxsaW2KGBkZybST/C8Z/rb2b5vG0NBQrn1Z7t+/j+LiYqXaKpKRkaHytESqSE9PR2FhoabLkMHPAb1r6vwcODk5qWU+EkqHenBwMAoKCtC0aVOsXbsWDRs2hFgsRkREBCZPnowdO3Zg3759EIvFmDp1KgIDA1GzZk21Fis0VlZWFZr+9XMAiN4FCwsLWFhYaLoMGfwc0LtWFT8HEkqHemxsLLS1tbF+/XrpbmaRSIQuXbrg+++/x5dffomCggIEBQVhzJgxlVZwWSRbz1lZWQrHv7mVrWhLvKz2b05Tq1YtmfaSs95L2/J/U0V3u+jq6lZoeqLy0tXVVfvuwori54Detar4OZBQ+kS5e/fuwcbGRuGx5I4dOwIATE1NMWrUKPVVV06S2m7duqVwvGS4pJ2+vj4sLS2RkpKicDf4m+1f/1nRcfOyjrcTERFVNqVDPS8vD3Xr1lU4TjK8fv360NKq1KvkyuTo6Ii6devi9OnTyMvLkxmXl5eH06dPw87ODjY2NtLh3t7eyMvLw6lTp+TmFxkZCQDw8vKSaQ8AUVFRpbav6B30iIiIVKHWBNb0sS2RSIRhw4YhNzcXQUFBMuOCgoKQm5uLESNGyAyX/D5//nyZEx+OHTuG2NhYdOjQQeYa+d69e8PIyAghISFIS0uTDk9LS8P69ethZmYGX1/fylg8IiKiMlX4NrHvQmhoKBISEgAAiYmJAICtW7dKrxn39PTE8OHDAQBTpkzB4cOHsWLFCly6dAnu7u64ePEioqKi0KxZM0ycOFFm3m3atMHw4cMRGhqKtm3bonPnznj48CH27dsHU1NTLFmyRKa9iYkJgoKCEBAQgLZt26J3794AXt0m9tmzZ/jtt9+kZ8ETERG9S+UK9cTERPTo0UOl8SKRCAcPHixfdf9fQkICtm/fLjPs1KlTMrvMJaGur6+P8PBwLFq0CIcOHcLJkydhYWGBzz//HDNnzlR4ed2KFSvg4uKCLVu2YN26ddDX14evry++/fZb2Nvby7UfOHAgzMzMsGzZMoSFhUEkEsHd3R2BgYFo166dSstIRERUUaLMzEyxMg1NTU0r1pFIhGfPnlVoHiTr4cOH2LRpE1w79Ya+aeXfsY8+XHkZT3D52D6MHj0alpaWmi5HBj8H9K5U5c+BhNJb6jNnzqzMOoiIiKiClA71WbNmVWYdREREVEEau/5s27ZtWLx4saa6JyIiEhyNhfrvv//OUCciIlIjzd0phoiIiNSKoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQ5Xqeujp16tRJ4bPKiYiISDUaC/Vp06ZpqmsiIiJBUirUt2/frpbO/P391TIfIiIikqdUqE+aNAkikajCnTHUiYiIKo9Soe7l5aWWUCciIqLKo1Soh4eHV3YdVAH52ZmaLoEEju8xoveDxk6Uo4rT09ODjo4Obp7+W9Ol0AdAR0cHenp6mi6DiMrAUH+PGRsbIyAgAPn5+Zou5b3y5MkTHDx4EH5+fqhdu7amy3lv6OnpwdjYWNNlEFEZGOrvOWNjY/6hVVHt2rVhaWmp6TKIiNSmwqF+7tw5bN++HZcuXcKzZ89QVFSksJ1IJMK///5b0e6IiIioFBUK9Z9++gnLly+HWCx+a1uePU9ERFS5VL73+5EjR/Dzzz+jdu3a+OWXX/DRRx9BJBLhwIED2Lx5MyZPngxTU1Po6elh6dKlOHjwoDrrJiIiojeoHOq//fYbRCIR1q9fj+HDh0uP67Zp0wY9e/bEvHnzcObMGXz00UeYN28e7Ozs1FY0ERERyVM51C9cuIDatWujbdu2pbapXbs2Nm7ciOzsbAQFBanaFRERESlB5VDPzMyEtbW19HcdnVeH5/Py8mTa1a9fH40aNcLff/NaaiIiosqkcqjXqlULBQUF0t9NTU0BACkpKXJtS0pK8OjRI1W7IiIiIiWoHOrW1tZIT0+X/t64cWMAwJ9//inTLjk5GTdv3uS11ERERJVM5VD38vJCRkaGdMu8V69eAIAlS5Zg7ty5OHr0KEJDQ9GnTx8UFxejffv2aimYiIiIFFM51Lt16wZTU1PExMQAABo2bIgvv/wSxcXF+PXXX+Hv74+pU6fi7t27sLCwwLfffqu2oomIiEieyjef8fT0RHJyssywuXPnwtXVFdu3b0dKSgr09PTg7e2NKVOm8HacRERElUzt937v27cv+vbtq+7ZEhER0VuovPs9Li4Oly9fVqrtlStXEBcXp2pXREREpASVQ93X1xczZ85Uqu2sWbPg5+enaldERESkBJVDHYBSD3JRpS0RERGVX4VCXVk5OTmoXr36u+iKiIjog1XpoZ6YmIikpCRYWVlVdldEREQfNKXPfl+7di3WrVsnM+zff/+Fu7t7qdPk5+fjyZMnAIBOnTqpWCIREREpQ+lQz8rKwt27d6W/i0QivHjxQmaYIiKRCJ07d8acOXNUr5KIiIjeSulQHzx4MFq1agXg1Ulvfn5+cHFxweLFixW2F4lEqFmzJuzt7WFiYqKWYomIiKh0Soe6ra0tbG1tpb97eXmhSZMm0qAnIiIizVL5jnLh4eHqrIOIiIgqSG23iU1LS8ONGzeQk5MDQ0NDODs784x3IiKid6jCoX7w4EEsXrwYV69elRvXuHFjzJgxAz169KhoN0RERPQWFbpOfcGCBRg5ciQSExMhFouhpaWFOnXqQEtLC2KxGFeuXMGIESOwYMECddVLREREpVA51GNiYhAUFAQAGDBgAGJjY5Geno5r164hPT0dsbGxGDhwIABg6dKlOHnypHoqJiIiIoVUDvXg4GCIRCLMmzcPwcHBaNy4MbS1tQEA2traaNy4MdatW4f58+dDLBYjJCREbUUTERGRPJVD/ezZszAzM8PEiRPLbDdhwgTUrl0bZ86cUbUrIiIiUoLKoZ6RkQE7OzuIRKIy24lEItja2iIjI0PVroiIiEgJKoe6iYkJUlNTlWp779493lWOiIiokqkc6s2aNcPjx4+xZcuWMttt3rwZjx49wieffKJqV0RERKQEpUN9+/btiIyMlP4+duxYiMVifPXVV5gxYwbu3Lkj0/7OnTsIDAxEYGAgRCIRxo4dq7aiiYiISJ7SN5+ZNGkSPD094ePjAwDo2LEjAgICEBwcjA0bNmDDhg3Q09NDnTp18PjxY+Tn5wN49fCXiRMnSqcjIiKiylGu3e9isVjm90WLFmH16tWws7ODWCzG8+fPkZKSgufPn0MsFsPe3h5r1qzhzWeIiIjegQrfJnbw4MEYPHgwbty4gRs3biA3NxcGBgZwdnZGgwYN1FEjERERKUFtD3RxcnKCk5OTumZXIa6urqWeme/t7S33hLmCggKsWLECO3fuRFpaGkxNTdGlSxd88803qFOnjsL57Nq1C+vWrUNSUhKqVasGDw8PzJ49Gx9//LG6F4eIiEgpagv1qsbIyEjhjXFefyY8AJSUlGDw4MGIjIxEixYt4Ofnh+TkZISGhiI6OhrHjx9H7dq1ZaZZunQp5s2bh3r16mHUqFHIzc3F3r170aVLFxw4cAAeHh6VumxERESKlCvUnzx5gu3bt6vcmb+/v8rTlpexsTFmz5791nZhYWGIjIxEv379sH79eunNdDZt2oRp06Zh3rx5WLFihbR9cnIyFi1ahAYNGiAyMhLGxsYAgDFjxqBTp06YMmUKEhISoKVVoWflEBERlVu5Qj05ORmTJ09WqSORSPROQ11ZoaGhAIDvvvtO5u54o0aNwq+//ordu3dj4cKF0NPTAwBs27YNL1++xPTp06WBDgBubm7o27cvwsLCkJCQAG9v73e7IERE9MEr99nvqv4rKSmprGVQqLCwENu2bcOyZcsQEhKCs2fPyrV58eIFzp49CycnJ7nd8iKRCO3bt0deXh4uXLggHR4bGwsA6NChg9z8JJftxcXFqXNRiIiIlFKuLXUPDw/89ddflVWLWqWnp8vtVWjWrBk2btwIe3t7AMDt27dRUlICBwcHhfOQDE9OToaXl5f0ZwMDA1hYWMi1d3R0lLZRxosXL5RbGFKrgoIC6f98Dd5/kteT6F1R59+OGjVqqGU+EoI8UW7IkCHw9PSEi4sL9PX1cfPmTaxevRo7d+6En58f4uPjYWhoiOzsbACQ2Y3+OiMjIwCQtpP8XNoZ8YaGhnLty3L//n0UFxcrvVykHpKHC6Wnp6OwsFDD1VBF8WFR9K6p82+Huq8aE2Soz5o1S+Z3Nzc3BAcHAwB27tyJLVu24PPPP9dEaTKsrKw0XcIHqXr16gAACwsLhXtc6P0ieT2J3pWq/LdDkKFemlGjRmHnzp04ffo0Pv/8c+mWeFZWlsL2ki1uSTvJz6Vtiefk5Mi1L4u6d7uQcnR1daX/8zV4/0leT6J3pSr/7figrrsyMzMDADx//hwAUL9+fWhpaeHWrVsK20uGS46VS37Ozc1Fenq6XHvJsfTX2xMREb0rH1SoS86Al5zprqenh08++QQ3btzA3bt3ZdqKxWL8/fff0NfXR9OmTaXDJZeqRUVFyc1f8hQ7Xs5GRESaoHSoZ2RkvBdnvl+/fl26Jf7m8Llz5wIA+vXrJx0+YsQIAMCPP/4o88Ca3377DXfu3EH//v2l16gDr07C09HRwbJly2R221+6dAl79uxBw4YN4enpqe7FIiIieivBHVPfs2cP1qxZAy8vL9SrVw81a9bEzZs3cezYMRQVFWHatGkyW9KDBw/Gvn378McffyAlJQXe3t64desWDh06BDs7O3zzzTcy82/QoAFmzZqFefPmoVWrVvDz85PeJhYAfvnlF95NjoiINEJwod66dWtcv34dly5dQkJCAp4/fw4zMzN06tQJY8eOlbtpjJaWFsLCwrB8+XLs3LkTa9asgampKYYNG4ZvvvlG7r7vAPDVV1/B1tYWa9euxaZNm1CtWjV4enpizpw5fKALERFpjOBCvVWrVmjVqlW5ptHV1cWsWbPkLoUry4ABAzBgwIDylkdERFRpuJ+YiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGegWcP38e/fv3h62tLaysrNCxY0fs27dP02UREdEHSkfTBbyvYmJi0LdvX9SoUQN9+vSBgYEBDh48iFGjRuHevXv44osvNF0iERF9YBjqKnj58iWmTJkCLS0thIeHw83NDQAwY8YM+Pj44KeffkLPnj1ha2ur4UqJiOhDwt3vKoiJicHt27fRr18/aaADgLGxMaZNm4bCwkJs375dgxUSEdGHiFvqKoiNjQUAdOjQQW6cj48PACAuLu6t83nx4oV6C6ticnNzkZeXp+ky5Dx79gwA8ODBAxQUFGi4Gnn6+vowMDDQdBnvDclrmPEgFfnZmZotRoGXhQV4WVSo6TLeKzrVqkOnuq6my5DzIi8HwKv3nLr+fteoUUMt85FgqKsgOTkZAODo6Cg3zsLCAgYGBrh169Zb53P//n0UFxervb6q4r///kNiYqKmyyjVX3/9pekSFHJxcUHjxo01XcZ74/nz5xCJRLh35aymS6EPgEgkQmZmJgoL1fNFzcnJSS3zkWCoqyA7OxsAYGRkpHC8oaGhtE1ZrKys1FpXVWNqaoqmTZtquoz3DrfUy8/Y2BgZGRmaLkOhFy9eVMk9QlWZrq6u2rdg1cXU1BSWlpaaLqNUDHUNqqpvWnWpUaMGateureky6ANQv3591K9fX9NlEGkcT5RTgWQLvbSt8ZycnFK34omIiCoLQ10FkmPpkmPrr0tPT0dubi4cHBzedVlERPSBY6irwNvbGwAQFRUlNy4yMlKmDRER0bsiyszMFGu6iPfNy5cv0bx5czx48ADHjh2TXquelZUFHx8f3L17F//88w/s7Ow0XCkREX1IGOoqKu02sampqfjpp594m1giInrnGOoVcO7cOSxcuBBnzpxBUVERXFxcMHnyZPTp00fTpRER0QeIoU5ERCQQPFGOiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDHUiIiKBYKgTEREJBEOdiIhIIBjqREREAsFQJyIiEgiGOhERkUAw1ImIiASCoU5ERCQQDPUP1LZt22BiYoJt27apfd4pKSkwMTHBxIkT1T5voqqge/fuMDEx0Vj/EydOhImJCVJSUjRWA1VNDPUqShKMZf1zdXXVWH2urq4a7V9VmZmZCAoKQqdOnWBvb4/atWvD0dERPXv2RHBwMHJzc99JHe/r+qsKJk+eDBMTE9jb26OgoEBhm5MnT8LExAQLFy5UOL4yQrEyvyiry82bNxEYGAgPDw/Uq1cP5ubmaNy4MYYPH44DBw6gpKSk0mvgl/7KpaPpAqhs9vb2GDBggMJxxsbGKs/X19cXLVq0gIWFhcrzKI2VlRXOnDkDIyMjtc+7IqKjozFy5EhkZGSgYcOG6NWrF2rVqoVnz54hPj4eM2fOxNq1a/Hvv/9qulQqRU5ODvbv3w+RSISMjAyEh4ejT58+77yOdevWIT8//533WxErV67E3LlzUVJSAg8PD7Rr1w41a9bEvXv3EB0djYMHD2Lo0KFYtWqVpkulCmCoV3EODg6YPXu22udrbGxcoS8FZalWrRqcnZ0rZd6qunz5MgYNGgQACAkJUfhF6eTJk/jxxx/fdWlUDvv27UNeXh4mT56MtWvXYuvWrRoJ9Xr16r3zPiti8+bN+Pbbb2Fra4vQ0FB8/PHHMuNfvnyJsLAwJCQkaKZAUhvufheI5cuXw8TEBP/73/9KHTdt2jTpsNJ2Ff77778YPnw4mjRpAnNzczg6OqJ9+/ZYunQpgP/bdZaamorU1FSZwwGSXZ2l7V6THIcsKirCwoUL4erqCnNzc3zyySfYsGGDwuV6+vQppkyZggYNGqBu3bpo3749Dh06VO5dnTNnzkR+fj4WL15c6p6P1q1b488//3zrOgJK372rjvUn8fvvv8PHxwfW1tawtraGj4/PW2s5ffo0fH19YWNjA0dHR0yfPl26RXn06FF06tQJVlZWcHJywnfffYeXL18qXBfh4eHw8/ODnZ0dLCws4OnpiZUrV6K4uFim3evr6K+//kKXLl1gY2NTaYcWtm7dCh0dHUyZMgWtW7dGdHQ07t69K9Nm4cKF6NGjBwBg8eLFMus4JSUFrq6u2L59OwDA3d1dOq579+7SeUh+v3//PgICAuDs7AxTU1OcPHkSgPwx9YkTJ2Ly5MkA/u/wgOTf63JycrBgwQJ4eHjA0tIStra26NOnT6lhevXqVQwcOBA2NjawtbVF//79kZiYWK51lpmZie+++w7Vq1fHrl275AIdAHR0dDB8+HCsWLFCZplKO0SxcOFCmJiYSNeHxIEDB9CtWzc0aNAAFhYWaNSoEXr27IkDBw4AePV+cXd3BwBs375dZj29Pq+8vDwsWLBAujexfv36GDBgAE6dOlVmLb///ju8vLxgaWkJNzc3rFu3DgAgFouxcuVKNG/eHBYWFmjWrJn0PfCmwsJCrFq1Cm3atIGVlRVsbGzw2Wef4fDhw3JtJevozp07WLlyJVq2bAlzc3ONHlrglrpATJkyBX///Td+++03+Pj4wNfXFwBw7tw5LFiwAI0aNcL8+fPLnMelS5fQpUsXaGtro1u3bqhXrx6ysrKQlJSEzZs346uvvoKxsbF0NzUAmTdvq1atlKp1zJgxOH/+PDp27AhtbW3s27cPX331FapVq4YRI0ZI2+Xm5qJ79+5ISkpCy5Yt4eXlhbS0NIwZMwYdOnRQet3cunUL8fHxsLGxwdChQ8tsq6urq/R836TO9TdjxgyEhITAyspKWvOhQ4cwefJkXLp0CYsXL5br/9y5c/jll1/QoUMHjBw5EidPnsTGjRuRk5ODrl27YtKkSejWrRtatGiBiIgI/Prrr9DX18fMmTNl5vPDDz9g+fLlsLKyQo8ePWBkZISEhAR8++23OHv2LLZs2SLX94EDBxAVFYUuXbpgzJgxyMnJUXk9liYpKQn//PMPOnfuDHNzcwwaNAjR0dHYtm2bzN6sVq1a4e7du9i+fTu8vb1l1quxsTEmTpyIsLAwXLlyBRMmTJDusbK1tZXpLyMjA507d4aJiQn69OmDgoICGBoaKqyte/fuyMrKwuHDh9GtWzeFX2oyMjLQrVs3XL16FR4eHhg1ahRycnJw+PBh9OjRA5s3b5Z+bgEgMTERXbt2RW5uLnr06AFHR0ecO3cOXbt2RePGjZVebwcPHkR2djb69++PRo0aldm2Iu//jRs3Yvr06bC0tISvry9q1aqF9PR0nD9/HuHh4ejZsydcXV0xYcIErFu3Dk2aNJH5IiVZ/y9evICfnx/OnTsHd3d3TJw4EY8ePcK+ffsQGRmJjRs3olevXnL9r127FrGxsejWrRtat26NQ4cOYdasWahZsyYuXbqEgwcPokuXLmjbti327NmDiRMnwtbWFt7e3tJ5FBQUoG/fvoiNjYWrqyuGDh2Kly9fIiIiAoMHD8aSJUswfvx4ub5nzJghfW927doVtWvXVnk9VhRDvYq7detWqSf7tGjRAh07dgQAaGlpYd26dWjVqhW++OILNGvWDIaGhhg7diy0tLSwYcMG6OnpldnXzp07UVBQgG3btsl82ADg2bNnAF5twcyePRthYWEAoNKhgfv37yM+Pl56zH3ChAnw9PTEqlWrZEJ9xYoVSEpKwsiRI2W2IIYMGYKePXsq3Z/k272Xlxe0tCpv55S61l9cXBxCQkLQsGFDRERESENn9uzZ6NixI4KDg9GzZ094eXnJTHf8+HGZvouKitCuXTvs3r0bkZGROHz4MJo1ayadV7NmzbBu3TpMmzYN1apVAwD8/fffWL58OXx8fBAaGgp9fX0Ar7Z0pk+fjk2bNuHAgQNy6//48ePYu3cv2rVrV5FVWKatW7cCAAYOHAgA6NGjB7766its27YNM2fOlL62rVu3BvBqS7BVq1Zy63jSpEm4fPkyrly5gokTJ8LOzk5hf4mJiRgyZAh+/fVXaGtrl1mbr6+vNNS7d++OIUOGyLWZMWMGrl69il9//RXDhw+XDn/8+DHat2+PqVOnomPHjqhRowYAIDAwENnZ2XKHi3788Uf8/PPPZdbzOsn7X7JeKktoaCiqV6+OkydPok6dOjLjJO9/Nzc3GBsbY926dXB1dVX4/v/ll19w7tw5DBgwAMHBwRCJRACAgIAAdOrUCVOmTIGPj4/cF6yEhATExMSgfv36ACD9O/jNN9/A3Nwc8fHx0rD19/dHx44dsXLlSplQX7JkCWJjYxEYGIg5c+ZI+87JyYGfnx+++eYb9OjRA3Xr1pXp+7///kNMTEyVOCzD3e9V3O3bt7F48WKF/44fPy7T1srKCitXrkRGRgbGjx+P6dOn4/bt2/jhhx/QpEkTpftUFP61atWq8LJIfPfddzIn0Tk5OaFly5a4ceOGzBberl27UL16dcyZM0dm+rZt25ZrS/3Ro0cAAGtr6wpWrpyKrj/JbsFZs2bJnPdgYmIi3aqWfCl4XevWrWW+TFSrVg09e/aEWCxG165dpYEOAIaGhujSpQsyMjKQlpYmHR4SEgLg1RcqSaADgEgkwvfffw+RSIQ9e/bI9d2tW7dKDfSioiLs3LkTRkZG0mU0MDBA9+7dce/ePZw4cULtfVavXh0//vjjWwNdGU+fPsXevXvRpk0bmUAHgDp16uCLL77AkydPpMuRmpqKuLg4NG7cWO5w0bRp08p1Psy7fP9Xq1ZN+gXxdeV9/1erVk36fpNwd3eHv78/srKyEB4eLjfdhAkTpIEOADY2NvDw8EB2djamT58us/XcvHlz1K9fH1euXJEOKykpwcaNG2Fvby8T6MCrz8uMGTNQWFiIQ4cOyfX9xRdfVIlAB7ilXuX5+Pgo/CNamu7du2P06NHYtGkTAKBz586YMGGCUtP27t0ba9euxdChQ9G7d2+0b98eXl5esLKyUqn20ig6pif5g5OVlQVDQ0NkZ2fj7t27aNSoEczNzeXat2zZElFRUWqtq6LUtf4uXboEQPHhDMnW1uXLl+XGKdrla2lp+dZxDx8+lP4xPHv2LPT19fH7778rrE1PTw83btyQG/7JJ58obK8uhw8fxpMnTzBs2DDplizwaotr165d2Lp1a7m+6CnDzs4OZmZmapnX+fPnUVxcjMLCQoV73m7dugUAuHHjBrp27SoNG09PT7m2BgYGcHV1RWxsrFpqU5e+ffviu+++g6enJ/r164fWrVvDw8OjXFfBZGdn486dO2jYsKHCLyGtW7fGli1bZE58lVDl/X/27Fnp7zdu3EBmZibq1q2LRYsWybV/+vSptN2bKvv9Xx4MdQHy9fWVhvq4ceOUnq558+b4888/8fPPP+OPP/6QnpTVrFkzzJ07F23atFFLfYo+5JKtIcmJWJIt9tKOTSkK+tJI2t6/f79cdZaXutZfTk4OtLS0FC67ubk5RCKRwmPWio73StZrWeOKioqkwzIyMvDy5UuFx+wl8vLy5Ia9ubtV3SS73t/8Q962bVtYWVnh8OHDyMjIgKmpqdr6VOcyZWRkAHi1K1zRyV4SknWbnZ0N4P16/3/xxRcwNTXFpk2bsGrVKqxcuRI6Ojro3LkzFixYILMVXRrJ+7q0dS+5BFdd7//XTxSVvEZXr17F1atXS61RE+//8mCoC0xmZia+/PJL6Ovro7i4GDNmzEBMTEypJ/i8ycvLC15eXsjPz8fZs2dx5MgRbNy4EQMHDkRCQoJSH0x1kNT75MkTheMluxSV4eHhAeDVseqSkhKlj6tL2r15xjfwf39036SO9WdoaIiSkhI8efJE7o/F48ePIRaLlX49y8vQ0BAikUi65ais13dVqtu9e/eke2XePFfhdTt37lR6r5Qy1LlMktfr888/x7x5897aXvLFV13v/7CwMMTExGDYsGFKT1fe979IJMKwYcMwbNgw6b0f9uzZg3379uHWrVuIi4t766EMyXp6/PixwvGS5a6M979knn5+fggNDS3XtJX5/i8vHlMXmKlTp+LevXtYuHAhfvzxR9y+fRtfffVVueejp6eH1q1bY/78+Zg2bRry8/Px999/S8dra2tX6t2njIyMYGtri1u3bin8gJ85c0bpeTk4OMDLywv37t1TeCz6da/foUxyOZKiLRzJLvLSVGT9ubm5AYDC3auSYZV1yVjz5s3x7NkzJCcnV8r8VREWFoaSkhJ4enpKQ+P1f/7+/gD+b2sekN/z8ybJeHW+h8vqs1mzZhCJRPjnn3+UmpfkHBhFl7rl5uYqPPxSGj8/PxgZGeHgwYO4fv16mW3V9f6vVasWfH198dtvv6FNmzZISkqSflEsaz0ZGRmhfv36uHXrlsJ+K/P937BhQxgZGeHChQsye6/eNwx1AQkNDcX+/fvRq1cvDB8+HOPHj0eXLl2wc+dO7N69+63TnzlzBi9evJAbLgnV1y93MTU1xdOnTxW2V5cBAwYoPAZ58uRJREZGlmteixYtgp6eHmbMmIG9e/cqbBMfHw8/Pz/p7x9//DFEIhH27t0rs5zJycnS619fp671JwmpxYsXy2wRZWVlSXeLS9qoW0BAAIBXW5SSM5Zfl56ejmvXrlVK34qIxWJs27YNIpEIa9euxcqVK+X+rV27Fp9++in+++8/XLhwAQCku+FfPwnwdZLx9+7dU1utZfVpYWGB3r174/Tp0/j1118hFovl2pw9exbPnz8H8OrmNl5eXvjvv/+wa9cumXY///wzsrKylK7LxMQEP/74IwoKCjBgwACFgVxcXIywsDCZ+1xITqx884vwgQMHEBcXJzePkydPyi1XUVGRdLe25P1vYmICkUhU6mvj7++PoqIi/PDDDzLzu3LlCsLCwmROllQnHR0djB49Gqmpqfjmm28UBntiYmKpexGqCu5+r+LKuqQNAP73v/+hRo0auHnzJmbPng0bGxuZy79Wr14Nb29vTJ8+HS1atChz9++KFSsQGxsLT09P2NnZoUaNGrh48SKio6NRv359mWto27RpgwsXLqBfv37w9PRE9erV4eXlJXN5SEVNmTIFBw8exKZNm3D16lV4enoiLS0N+/fvR9euXXHkyBGld6W7ublhx44dGDlyJEaPHo0lS5bAy8sLpqamyMjIwKlTp5CYmAgHBwfpNHXr1kW/fv2we/dutGvXDj4+Pnj8+DHCw8Ph4+ODgwcPyvShrvXn7e2N8ePHIyQkBF5eXujRowfEYjEOHTqEtLQ0BAQEqHU9v65jx44IDAxEUFAQmjZtio4dO6JevXp49uwZbt26hYSEBHzzzTdo2LBhpfT/ppiYGKSkpMDb27vM9+6QIUNw5swZbN26FU2bNoWzszPq1q2LvXv3QldXF1ZWVhCJRBg/fjyMjY3Rpk0brFy5ElOnToWfnx9q1qyJevXqyR2zL49PP/0Uenp6WLt2LTIzM6XHwwMDAwEAy5Ytw40bN/Ddd99hx44d+PTTT2FsbIy0tDRcuHABycnJuHbtGmrWrAkAWLp0Kbp27YoJEyYgPDxcep36hQsX4OnpWa67v40cORI5OTmYO3cu2rZtCy8vL7i5uUFPTw/3799HTEwM7t+/L3Nmfrdu3WBvb4+wsDCkpaXBzc0N169fR0xMDDp37oyIiAi518DIyAjNmzdHvXr1UFRUhBMnTiApKQk9e/aUXoduYGCAZs2aIT4+HuPHj4ejoyO0tLQwcOBA2NraYsqUKYiIiMDOnTtx/fp1tG3bFo8fP8a+ffvw8uVLBAcHV9rhp9mzZ+PixYsIDg5GREQEvLy8UKdOHdy/fx+JiYm4cuUKjh07VqWOob+JoV7FSS5pK83EiROhpaWFMWPGID8/H7t27ZK5i1Xt2rWxbt069OnTB+PGjcNff/0FHR3FL/uYMWNgZGSEc+fOIT4+HmKxGDY2Npg+fTomTZokc4JbYGAgMjMzcfToUSQkJKC4uBgzZ85Ua9gYGhri8OHD+OGHH3D48GFcuHABjRo1woYNG3Dnzh0cOXKkXB/utm3b4vz589iwYQMiIiKwd+9e5ObmwsjICC4uLli8eLHczWl+/fVX1KpVC/v27cOGDRvQoEEDrFixApaWlnKhrs71t2TJEri5uWHTpk3Sm700atQIs2fPfusNdCrq66+/hre3N9atW4fo6GhkZWWhVq1asLOzw6xZs9C/f/9K7f91kl3qgwcPLrNd7969MWvWLPzxxx+YP38+9PT0sHXrVnz//ffYs2eP9MSqAQMGwNjYGJ06dcKPP/6ILVu2YNWqVSgqKoK3t3eFQt3U1BRbtmzBokWLEBoaKr2TnyTUTU1NERERgfXr12Pv3r3YvXs3SkpKYG5ujiZNmiAwMFDmbHsXFxccOXIEc+fORWRkJKKiouDh4YEjR45g5cqV5b6l6xdffIGuXbsiJCQEJ0+exNatW1FQUIA6deqgadOmWLhwocyeKj09Pezfvx9z5sxBTEwMzp49i+bNm+Pw4cM4cuSIXKh///33OH78OM6dO4cjR46gZs2asLe3x88//yx3LD84OBhz5szB0aNHkZ2dDbFYDA8PD9ja2qJGjRo4ePAgVqxYgX379mHNmjXQ09ODt7c3pk2bpvCKAHXR1dXFH3/8ga1bt2LHjh04dOiQdB01atQIo0ePhouLS6X1rw6izMxM+f1ARFXc+PHjsWvXLpw+ffqdbTUSEVV1PKZOVdrDhw/lhsXGxmLPnj1wcnJioBMRvYa736lK69+/P/T09ODq6oqaNWvi2rVrOH78OLS1tbFkyRJNl0dEVKVw9ztVaWvWrMHu3btx+/Zt5ObmwtjYGC1btsS0adPQvHlzTZdHRFSlMNSJiIgEgsfUiYiIBIKhTkREJBAMdSIiIoFgqBMREQkEQ52IiEggGOpEH5iUlBSYmJjI3E64PLZt2wYTE5NKeahGVTVx4kSYmJiU+RwGoqqAoU5USRYsWCANz6CgoFLbpaSkYOHChVizZk2pbTIzM7Fw4cJKD5U///wTCxcuxMmTJyu1H02SvCZl/WvVqpWmyyRSCe8oR1QJSkpKsH37dunvYWFh+OqrryASieTa3r17F4sXL0a9evUwadIkhfN7/bGrs2fPrlBt1apVg5OTk8Jx4eHh0rpbt26tsI2RkRGcnJxgY2NToTo0zcXFReYhO697/Wl9RO8ThjpRJYiOjkZqaipq1qyJly9f4vbt24iNjS01KN8lKysr/PPPPypP36NHD/To0UONFWnG4sWLq8TrQaRO3P1OVAl+//13AICvry+6du0qM4yIqLIw1InULDMzE+Hh4QBePQfc398fAHDo0CFkZ2fLtO3evbt0qzc1NVXu2O7JkycxceJEuLu7S6d5s822bdvkxqWkpODcuXMYPnw4nJ2dUatWLenxeEUnykmGSXa9L168WKYPV1dXadu3nSiXl5eH5cuXo127dqhXrx7q1q2LFi1aYM6cOQqfugfInoiWn5+PBQsWoHnz5rCwsICjoyNGjRqF5ORkpdb/uxYfH49vv/0WHTp0QMOGDVGnTh04OTlhwIAB+Ouvv8qcNj09Hf/73//g4uICCwsLuLq6YtasWdJzKExMTDBx4sR3tCQkBNz9TqRmu3fvxosXL2BtbY02bdqgpKQEderUwePHj7F3716MHDlS2tbFxQUZGRlITEyErq4umjZtKjMvIyMjNGjQAE2bNsWFCxcAAB4eHjJtzM3N5Wo4ePAgfvjhB9SoUQMNGjSAkZGRwuP5EjVq1ICHhweSk5Px+PFj2NjYyBwzt7CwUGrZHzx4gN69eyMpKQkikQjOzs7Q1dXF1atXsWbNGuzYsQO7du0q9WE8OTk56NSpE/777z84OzvDwcEBN27cwL59+xAdHY0TJ07A1tZWqVrelaFDh+LZs2cwNTWFpaUlLC0tkZaWhoiICEREROB///sfvv/+e7npbt26he7du+PBgwfQ1tZGo0aNIBaLERISgoiICHTu3FkDS0PvO4Y6kZpJdrMPHDgQWlpa0NLSQv/+/bFmzRr8/vvvMqEeFBSEkydPokePHjA3N8eRI0fk5ufu7o5+/fpJt9YVtXnT3LlzMXHiRHzzzTeoUaMGACA/P7/U9hYWFjhy5AgmTpyI7du3Y8iQISqdkDdu3DgkJSXB0dERW7duhYuLCwDg0aNHGDt2LGJiYjB8+HAkJCTA2NhYbvr169fDxcUF586dk56sdufOHfTv3x83btzAggULsG7dunLXVZnmzp2LNm3aoH79+jLDT5w4gXHjxmH58uXo1q0bWrRoIR0nFosxbtw4PHjwAK6urti6dat0+uTkZAwePBgbN258h0tBQsHd70RqdOXKFVy8eBEApLvdgVe74QHg7NmzSEpKqvQ62rZti3nz5kkDHQD09PQqtc/4+HjExsYC+L9wljA3N0doaCiMjIxw//59hIaGKpyHlpYWNm/eLHP2ef369fHtt98CUO4LjbJ69OhR6iVtmZmZSs9n+PDhcoEOAO3atZPW/fqVEABw8uRJnDt3DtWqVZMJdABwdHTEli1bUFxcrMpi0QeOW+pEaiTZSm/evLnMZWNNmjSBq6srLl++jG3btuGnn36q1DqGDRtWqfNXJCIiAgDg6emJZs2ayY03MTHB0KFDsWbNGkREROCLL76Qa9OhQwfY29vLDf/0008BvDpfISMjA6amphWut6xL2nR0yvenMSkpCfv378d///2HjIwMvHz5EgCk51BcunRJpn1kZCQAKNzCB4BGjRqhZcuWSEhIKFcdRAx1IjUpLCzE7t27AchupUsMHjwYs2fPxs6dO/H999+XOzjKo1GjRpU279LcuHEDAPDRRx+V2kay9S5p+6YGDRooHP76eQM5OTlqCXV1XdI2d+5c/PLLLxCLxaW2efbsmczvkuV//QTEN7m5uTHUqdy4+51ITf766y88ffoU1atXR9++feXG9+/fH9WqVcOjR49w9OjRSq2lZs2alTp/RXJzcwEoPnFPwtLSUqbtm0qrW0vr//5UlRWe79qePXuwYsUKiEQizJw5E7GxsUhNTcWzZ8+QmZmJAwcOAACKiopkpsvLywMAGBgYlDpvQ0PDyiucBItb6kRqItn1XlhYqHCX6ptthXbvdElAPXr0qNQ2kkvaygqz90lYWBgAYPLkyQpPLMzIyFA4nb6+PoDSv9wAr/ZIEJUXQ51IDe7fv4+oqCgAgJmZGbS1tRW2Ky4uxtOnT3Hs2DE8evQI5ubmZV5qJqFMG3WoSD/Ozs4IDw/H1atXS22TmJgobSsEKSkpAAAvLy+F40u7c5/kfIsrV66UOu/Lly9XsDr6EHH3O5EabN++HcXFxTAzM0NSUhKuX7+u8N+1a9dQp04dvHz5Ejt27ADwf7ucy7rk7PXd0s+fP6+05VCmltJIrqtOSEjA+fPn5cZnZmZK92YI5RpsyRUF6enpcuOePHki3ZJ/k4+PD4BXtxOWfDF43fXr13Hq1Ck1VkofCoY6kRpI/nhLjpuXRkdHBwMGDAAA6Z3g7O3tIRKJ8OTJk1K33MzMzKRnap84cUKNlcuSnHmekJCAwsLCck3r6ekpfbrZuHHjZLbYHz9+jFGjRiE7OxtWVlYaOTu/Mnh7ewMAli1bhps3b0qH37lzBwMHDiz1y1Hr1q3RvHlzFBUVYfjw4bh796503K1btzBixIhS9/YQlYWhTlRBcXFx0luYDh069K3tJW2uXbuGM2fOwNTUVLrl2qFDB7Rp0wbdu3dH9+7dpZdCiUQiDBw4UDq9l5eXtM3x48fVtiw9e/ZEzZo18c8//8DFxQVdunRB9+7dMXr0aKWmX79+PRo1aoTk5GR4eXnBw8MDbdq0gYuLC/7++2+YmpoiNDRU4Y1n3kdTpkyBhYUFUlNT4eHhAQ8PD3h5eaFZs2a4efNmqZcuikQihISEwNLSEhcvXkTTpk3RqlUreHl5oXnz5njx4oV0nTPcqTwY6kQVJNni/vjjj9GkSZO3tv/oo4/wySefAPi/k+uCg4Mxbtw4WFlZISkpCXFxcYiLi0NWVpZ0up9++glfffUVGjRogFu3bknbKNr1qyobGxvs3bsXnTp1glgsxj///IO4uDiln+pWt25dREZG4rvvvoObmxvu3buH69evw87ODhMnTkR8fHypt4h9H9WtWxfHjh3DgAEDYGJiguTkZGRnZ8Pf3x8xMTFlXlro4OCA6OhojBo1Cubm5rh+/Tqys7MxZswYREVFSff48Cx4Kg9RZmZm1bk+hIiIAAADBgxAREQEFi1ahAkTJmi6HHpPcEudiKiKuXv3rvTcidLOrCdShKFORKQBKSkpWLlyJZ4+fSoz/PLlyxg0aBAKCwvh6ekJNzc3DVVI7yPufiei9056ejpGjBhRrmnU+TAYdUhMTISXlxe0tLTg6OgIY2NjPHr0SHomvI2NDQ4dOqTwXvhEpWGoE9F7JyUlRfooWmWV58lr70J2djZWrVqFEydOICUlBRkZGahWrRrs7e3RtWtXTJo0CbVq1dJ0mfSeYagTEREJBI+pExERCQRDnYiISCAY6kRERALBUCciIhIIhjoREZFAMNSJiIgEgqFOREQkEAx1IiIigfh/+UtsFPZTGmkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 515.556x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.catplot(y=\"Total_Revolving_Bal\", x=\"Attrition_Flag\", data=df, kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
